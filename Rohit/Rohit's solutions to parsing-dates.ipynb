{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
    "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
   },
   "source": [
    "### All days of the challange:\n",
    "\n",
    "* [Day 1: Handling missing values](https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values)\n",
    "* [Day 2: Scaling and normalization](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)\n",
    "* [Day 3: Parsing dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)\n",
    "* [Day 4: Character encodings](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/)\n",
    "* [Day 5: Inconsistent Data Entry](https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry/)\n",
    "___\n",
    "Welcome to day 3 of the 5-Day Data Challenge! Today, we're going to work with dates. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n",
    "\n",
    "> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n",
    "\n",
    "Here's what we're going to do today:\n",
    "\n",
    "* [Get our environment set up](#Get-our-environment-set-up)\n",
    "* [Check the data type of our date column](#Check-the-data-type-of-our-date-column)\n",
    "* [Convert our date columns to datetime](#Convert-our-date-columns-to-datetime)\n",
    "* [Select just the day of the month from our column](#Select-just-the-day-of-the-month-from-our-column)\n",
    "* [Plot the day of the month to check the date parsing](#Plot-the-day-of-the-month-to-the-date-parsing)\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
    "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
   },
   "source": [
    "# Get our environment set up\n",
    "________\n",
    "\n",
    "The first thing we'll need to do is load in the libraries and datasets we'll be using. For today, we'll be working with two datasets: one containing information on earthquakes that occured between 1965 and 2016, and another that contains information on landslides that occured between 2007 and 2016.\n",
    "\n",
    "> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
    "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date      Time  Latitude  Longitude        Type   Depth  \\\n",
      "0      01/02/1965  13:44:18   19.2460   145.6160  Earthquake  131.60   \n",
      "1      01/04/1965  11:29:49    1.8630   127.3520  Earthquake   80.00   \n",
      "2      01/05/1965  18:05:58  -20.5790  -173.9720  Earthquake   20.00   \n",
      "3      01/08/1965  18:49:43  -59.0760   -23.5570  Earthquake   15.00   \n",
      "4      01/09/1965  13:32:50   11.9380   126.4270  Earthquake   15.00   \n",
      "...           ...       ...       ...        ...         ...     ...   \n",
      "23407  12/28/2016  08:22:12   38.3917  -118.8941  Earthquake   12.30   \n",
      "23408  12/28/2016  09:13:47   38.3777  -118.8957  Earthquake    8.80   \n",
      "23409  12/28/2016  12:38:51   36.9179   140.4262  Earthquake   10.00   \n",
      "23410  12/29/2016  22:30:19   -9.0283   118.6639  Earthquake   79.00   \n",
      "23411  12/30/2016  20:08:28   37.3973   141.4103  Earthquake   11.94   \n",
      "\n",
      "       Depth Error  Depth Seismic Stations  Magnitude Magnitude Type  ...  \\\n",
      "0              NaN                     NaN        6.0             MW  ...   \n",
      "1              NaN                     NaN        5.8             MW  ...   \n",
      "2              NaN                     NaN        6.2             MW  ...   \n",
      "3              NaN                     NaN        5.8             MW  ...   \n",
      "4              NaN                     NaN        5.8             MW  ...   \n",
      "...            ...                     ...        ...            ...  ...   \n",
      "23407          1.2                    40.0        5.6             ML  ...   \n",
      "23408          2.0                    33.0        5.5             ML  ...   \n",
      "23409          1.8                     NaN        5.9            MWW  ...   \n",
      "23410          1.8                     NaN        6.3            MWW  ...   \n",
      "23411          2.2                     NaN        5.5             MB  ...   \n",
      "\n",
      "       Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
      "0                             NaN            NaN                  NaN   \n",
      "1                             NaN            NaN                  NaN   \n",
      "2                             NaN            NaN                  NaN   \n",
      "3                             NaN            NaN                  NaN   \n",
      "4                             NaN            NaN                  NaN   \n",
      "...                           ...            ...                  ...   \n",
      "23407                        18.0          42.47                0.120   \n",
      "23408                        18.0          48.58                0.129   \n",
      "23409                         NaN          91.00                0.992   \n",
      "23410                         NaN          26.00                3.553   \n",
      "23411                       428.0          97.00                0.681   \n",
      "\n",
      "       Horizontal Error  Root Mean Square            ID  Source  \\\n",
      "0                   NaN               NaN  ISCGEM860706  ISCGEM   \n",
      "1                   NaN               NaN  ISCGEM860737  ISCGEM   \n",
      "2                   NaN               NaN  ISCGEM860762  ISCGEM   \n",
      "3                   NaN               NaN  ISCGEM860856  ISCGEM   \n",
      "4                   NaN               NaN  ISCGEM860890  ISCGEM   \n",
      "...                 ...               ...           ...     ...   \n",
      "23407               NaN            0.1898    NN00570710      NN   \n",
      "23408               NaN            0.2187    NN00570744      NN   \n",
      "23409               4.8            1.5200    US10007NAF      US   \n",
      "23410               6.0            1.4300    US10007NL0      US   \n",
      "23411               4.5            0.9100    US10007NTD      US   \n",
      "\n",
      "      Location Source Magnitude Source     Status  \n",
      "0              ISCGEM           ISCGEM  Automatic  \n",
      "1              ISCGEM           ISCGEM  Automatic  \n",
      "2              ISCGEM           ISCGEM  Automatic  \n",
      "3              ISCGEM           ISCGEM  Automatic  \n",
      "4              ISCGEM           ISCGEM  Automatic  \n",
      "...               ...              ...        ...  \n",
      "23407              NN               NN   Reviewed  \n",
      "23408              NN               NN   Reviewed  \n",
      "23409              US               US   Reviewed  \n",
      "23410              US               US   Reviewed  \n",
      "23411              US               US   Reviewed  \n",
      "\n",
      "[23412 rows x 21 columns]\n",
      "        id     date   time continent_code   country_name country_code  \\\n",
      "0       34   3/2/07  Night            NaN  United States           US   \n",
      "1       42  3/22/07    NaN            NaN  United States           US   \n",
      "2       56   4/6/07    NaN            NaN  United States           US   \n",
      "3       59  4/14/07    NaN            NaN         Canada           CA   \n",
      "4       61  4/15/07    NaN            NaN  United States           US   \n",
      "...    ...      ...    ...            ...            ...          ...   \n",
      "1688  7535  12/7/15    NaN            NaN  United States           US   \n",
      "1689  7537  2/22/16   0:00            NaN  United States           US   \n",
      "1690  7539  2/23/16    NaN            NaN  United States           US   \n",
      "1691  7540  2/26/16  21:06            NaN  United States           US   \n",
      "1692  7541   3/2/16   8:00            NaN  United States           US   \n",
      "\n",
      "      state/province  population         city/town  distance  ...  \\\n",
      "0           Virginia       16000       Cherry Hill   3.40765  ...   \n",
      "1               Ohio       17288  New Philadelphia   3.33522  ...   \n",
      "2       Pennsylvania       15930       Wilkinsburg   2.91977  ...   \n",
      "3             Quebec       42786       Ch√¢teauguay   2.98682  ...   \n",
      "4           Kentucky        6903         Pikeville   5.66542  ...   \n",
      "...              ...         ...               ...       ...  ...   \n",
      "1688  North Carolina        1646             Tryon   7.80866  ...   \n",
      "1689   West Virginia       51400        Charleston   6.84721  ...   \n",
      "1690   West Virginia        2406             Welch  14.19735  ...   \n",
      "1691   West Virginia        1048            Athens  12.00678  ...   \n",
      "1692         Vermont        2066           Windsor   1.78429  ...   \n",
      "\n",
      "                                    geolocation  hazard_type  \\\n",
      "0     (38.600900000000003, -77.268199999999993)    Landslide   \n",
      "1     (40.517499999999998, -81.430499999999995)    Landslide   \n",
      "2                (40.4377, -79.915999999999997)    Landslide   \n",
      "3     (45.322600000000001, -73.777100000000004)    Landslide   \n",
      "4     (37.432499999999997, -82.493099999999998)    Landslide   \n",
      "...                                         ...          ...   \n",
      "1688  (35.221899999999998, -82.322599999999994)    Landslide   \n",
      "1689  (38.398699999999998, -81.584800000000001)    Landslide   \n",
      "1690             (37.409599999999998, -81.4268)    Landslide   \n",
      "1691  (37.501100000000001, -81.109300000000005)    Landslide   \n",
      "1692             (43.4771, -72.406599999999997)    Landslide   \n",
      "\n",
      "          landslide_type landslide_size   trigger storm_name injuries  \\\n",
      "0              Landslide          Small      Rain        NaN      NaN   \n",
      "1              Landslide          Small      Rain        NaN      NaN   \n",
      "2              Landslide          Small      Rain        NaN      NaN   \n",
      "3     Riverbank collapse          Small      Rain        NaN      NaN   \n",
      "4              Landslide          Small  Downpour        NaN      NaN   \n",
      "...                  ...            ...       ...        ...      ...   \n",
      "1688            Rockfall          Small       NaN        NaN      0.0   \n",
      "1689            Mudslide          Small   Unknown        NaN      0.0   \n",
      "1690           Landslide          Small      Rain        NaN      0.0   \n",
      "1691            Rockfall          Small   Unknown        NaN      0.0   \n",
      "1692            Rockfall          Small   Unknown        NaN      0.0   \n",
      "\n",
      "     fatalities                 source_name  \\\n",
      "0           NaN                  NBC 4 news   \n",
      "1           NaN              Canton Rep.com   \n",
      "2           NaN  The Pittsburgh Channel.com   \n",
      "3           NaN                   Le Soleil   \n",
      "4           0.0      Matthew Crawford (KGS)   \n",
      "...         ...                         ...   \n",
      "1688        0.0        Tryon Daily Bulletin   \n",
      "1689        0.0          Charleston Gazette   \n",
      "1690        0.0   Bluefield Daily Telegraph   \n",
      "1691        0.0   Bluefield Daily Telegraph   \n",
      "1692        0.0                 Valley News   \n",
      "\n",
      "                                            source_link  \n",
      "0         http://www.nbc4.com/news/11186871/detail.html  \n",
      "1     http://www.cantonrep.com/index.php?ID=345054&C...  \n",
      "2     https://web.archive.org/web/20080423132842/htt...  \n",
      "3     http://www.hebdos.net/lsc/edition162007/articl...  \n",
      "4                                                   NaN  \n",
      "...                                                 ...  \n",
      "1688  http://www.tryondailybulletin.com/2016/02/26/u...  \n",
      "1689  http://www.wvgazettemail.com/news/20160222/us-...  \n",
      "1690  http://www.bdtonline.com/news/officials-cautio...  \n",
      "1691  http://www.bdtonline.com/news/rockslide-snarls...  \n",
      "1692  http://www.vnews.com/home/21353539-95/loose-ledge  \n",
      "\n",
      "[1693 rows x 23 columns]\n",
      "      Number                       Name         Country  \\\n",
      "0     210010  West Eifel Volcanic Field         Germany   \n",
      "1     210020            Chaine des Puys          France   \n",
      "2     210030        Olot Volcanic Field           Spain   \n",
      "3     210040   Calatrava Volcanic Field           Spain   \n",
      "4     211001                 Larderello           Italy   \n",
      "...      ...                        ...             ...   \n",
      "1503  390130                 Zavodovski  United Kingdom   \n",
      "1504  390140        Protector Seamounts  United Kingdom   \n",
      "1505  390812            Rittmann, Mount      Antarctica   \n",
      "1506  390829          James Ross Island      Antarctica   \n",
      "1507  390847                   Melville      Antarctica   \n",
      "\n",
      "                              Region                 Type  \\\n",
      "0     Mediterranean and Western Asia              Maar(s)   \n",
      "1     Mediterranean and Western Asia         Lava dome(s)   \n",
      "2     Mediterranean and Western Asia  Pyroclastic cone(s)   \n",
      "3     Mediterranean and Western Asia  Pyroclastic cone(s)   \n",
      "4     Mediterranean and Western Asia  Explosion crater(s)   \n",
      "...                              ...                  ...   \n",
      "1503                      Antarctica        Stratovolcano   \n",
      "1504                      Antarctica            Submarine   \n",
      "1505                      Antarctica               Shield   \n",
      "1506                      Antarctica               Shield   \n",
      "1507                      Antarctica        Stratovolcano   \n",
      "\n",
      "         Activity Evidence Last Known Eruption  Latitude  Longitude  \\\n",
      "0           Eruption Dated            8300 BCE    50.170      6.850   \n",
      "1           Eruption Dated            4040 BCE    45.775      2.970   \n",
      "2        Evidence Credible             Unknown    42.170      2.530   \n",
      "3           Eruption Dated            3600 BCE    38.870     -4.020   \n",
      "4        Eruption Observed             1282 CE    43.250     10.870   \n",
      "...                    ...                 ...       ...        ...   \n",
      "1503     Eruption Observed             2016 CE   -56.300    -27.570   \n",
      "1504     Eruption Observed             1962 CE   -55.912    -28.167   \n",
      "1505  Unrest / Pleistocene             Unknown   -73.450    165.500   \n",
      "1506     Evidence Credible             Unknown   -64.150    -57.750   \n",
      "1507    Evidence Uncertain             Unknown   -62.020    -57.670   \n",
      "\n",
      "      Elevation (Meters)                Dominant Rock Type  \\\n",
      "0                    600                           Foidite   \n",
      "1                   1464             Basalt / Picro-Basalt   \n",
      "2                    893  Trachybasalt / Tephrite Basanite   \n",
      "3                   1117             Basalt / Picro-Basalt   \n",
      "4                    500                           No Data   \n",
      "...                  ...                               ...   \n",
      "1503                 551             Basalt / Picro-Basalt   \n",
      "1504                 -55                          Rhyolite   \n",
      "1505                2600                               NaN   \n",
      "1506                1630             Basalt / Picro-Basalt   \n",
      "1507                 549                               NaN   \n",
      "\n",
      "                                  Tectonic Setting  \n",
      "0           Rift Zone / Continental Crust (>25 km)  \n",
      "1           Rift Zone / Continental Crust (>25 km)  \n",
      "2          Intraplate / Continental Crust (>25 km)  \n",
      "3          Intraplate / Continental Crust (>25 km)  \n",
      "4     Subduction Zone / Continental Crust (>25 km)  \n",
      "...                                            ...  \n",
      "1503     Subduction Zone / Oceanic Crust (< 15 km)  \n",
      "1504     Subduction Zone / Oceanic Crust (< 15 km)  \n",
      "1505       Intraplate / Continental Crust (>25 km)  \n",
      "1506       Intraplate / Continental Crust (>25 km)  \n",
      "1507       Intraplate / Continental Crust (>25 km)  \n",
      "\n",
      "[1508 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "# read in our data\n",
    "earthquakes = pd.read_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\earthquake.csv')\n",
    "landslides = pd.read_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\catalog.csv')\n",
    "volcanos = pd.read_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\volcanos.csv')\n",
    "print(earthquakes)\n",
    "print(landslides)\n",
    "print(volcanos)\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "604ac3a4-b1d9-4264-b312-4bbeecdeec00",
    "_uuid": "03ce3b4afe87d98f777172c2c7be066a66a0b237"
   },
   "source": [
    "Now we're ready to look at some dates! (If you like, you can take this opportunity to take a look at some of the data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9b87a77d-e5e5-4581-9cd3-0e7339fe1516",
    "_uuid": "742028572a307a42ce40db0102171bc219b05282"
   },
   "source": [
    "# Check the data type of our date column\n",
    "___\n",
    "\n",
    "For this part of the challenge, I'll be working with the `date` column from the `landslides` dataframe. The very first thing I'm going to do is take a peek at the first few rows to make sure it actually looks like it contains dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "e6b7eb39-c3e3-40a1-b0a5-91cfcd2d42da",
    "_uuid": "93a08de7a6a621e4b07968c07c1cc612936c6027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3/2/07\n",
      "1    3/22/07\n",
      "2     4/6/07\n",
      "3    4/14/07\n",
      "4    4/15/07\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the first few rows of the date column\n",
    "print(landslides['date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbdacb7c-10d4-4b0a-8f6b-6d4a940ca446",
    "_uuid": "d88dbc08ab145fd20f86073b027c53f40fd306bc"
   },
   "source": [
    "Yep, those are dates! But just because I, a human, can tell that these are dates doesn't mean that Python knows that they're dates. Notice that the at the bottom of the output of `head()`, you can see that it says that the data type of this  column is \"object\". \n",
    "\n",
    "> Pandas uses the \"object\" dtype for storing various types of data types, but most often when you see a column with the dtype \"object\" it will have strings in it. \n",
    "\n",
    "If you check the pandas dtype documentation [here](http://pandas.pydata.org/pandas-docs/stable/basics.html#dtypes), you'll notice that there's also a specific `datetime64` dtypes. Because the dtype of our column is `object` rather than `datetime64`, we can tell that Python doesn't know that this column contains dates.\n",
    "\n",
    "We can also look at just the dtype of your column without printing the first few rows if we like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "56a047f4-cbf7-4914-951c-a04310ee7432",
    "_uuid": "e2ab2ac80aaac7b165b3af64edb75d29f2612482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data type of our date column\n",
    "landslides['date'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "99a207db-3db0-4343-9805-58753f51f6e8",
    "_uuid": "06e6483764014a04e7a1f34525e2f12aee5fdab8"
   },
   "source": [
    "You may have to check the [numpy documentation](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind) to match the letter code to the dtype of the object. \"O\" is the code for \"object\", so we can see that these two methods give us the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "8987e921-0c37-4c0f-ba68-e4e26d8d1a1b",
    "_uuid": "a2a983470b318469993b75b450bab28c12b59ae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn! Check the data type of the Date column in the earthquakes dataframe\n",
    "# (note the capital 'D' in date!)\n",
    "earthquakes['Date'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb3b552b-411b-4fc0-b1e6-a3a8156fd459",
    "_uuid": "0939ce269aef7001e35cc8f2a5f1eed1f6160940"
   },
   "source": [
    "# Convert our date columns to datetime\n",
    "___\n",
    "\n",
    "Now that we know that our date column isn't being recognized as a date, it's time to convert it so that it *is* recognized as a date. This is called \"parsing dates\" because we're taking in a string and identifying its component parts.\n",
    "\n",
    "We can pandas what the format of our dates are with a guide called as [\"strftime directive\", which you can find more information on at this link](http://strftime.org/). The basic idea is that you need to point out which parts of the date are where and what punctuation is between them. There are [lots of possible parts of a date](http://strftime.org/), but the most common are `%d` for day, `%m` for month, `%y` for a two-digit year and `%Y` for a four digit year.\n",
    "\n",
    "Some examples:\n",
    "\n",
    " * 1/17/07 has the format \"%m/%d/%y\"\n",
    " * 17-1-2007 has the format \"%d-%m-%Y\"\n",
    " \n",
    " Looking back up at the head of the `date` column in the landslides dataset, we can see that it's in the format \"month/day/two-digit year\", so we can use the same syntax as the first example to parse in our dates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_cell_guid": "f955aa17-ede7-4457-a913-ba1c44f8846d",
    "_uuid": "a471aae50241b245caa0c60fbb19821372682b76",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a new column, date_parsed, with the parsed dates\n",
    "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format = \"%m/%d/%y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09c1c55c-3883-4f5e-8ea9-e914b09416b6",
    "_uuid": "50feaed5f874d8c09f983ad3172febdc54f4f0bb"
   },
   "source": [
    "Now when I check the first few rows of the new column, I can see that the dtype is `datetime64`. I can also see that my dates have been slightly rearranged so that they fit the default order datetime objects (year-month-day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_cell_guid": "5a6c6244-b724-4a70-b356-6e3fb1e61270",
    "_uuid": "2bff07787e5aa5ad2b6484c5bcee18b5b2f283bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2007-03-02\n",
       "1   2007-03-22\n",
       "2   2007-04-06\n",
       "3   2007-04-14\n",
       "4   2007-04-15\n",
       "Name: date_parsed, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first few rows\n",
    "landslides['date_parsed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7bd8f8b6-8a60-4a12-b94b-4100188845da",
    "_uuid": "fc95b22f0f4d7a6bc0cb1a7cc55abfb204cc81f9"
   },
   "source": [
    "Now that our dates are parsed correctly, we can interact with them in useful ways.\n",
    "\n",
    "___\n",
    "* **What if I run into an error with multiple date formats?** While we're specifying the date format here, sometimes you'll run into an error when there are multiple date formats in a single column. If that happens, you have have pandas try to infer what the right date format should be. You can do that like so:\n",
    "\n",
    "`landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)`\n",
    "\n",
    "* **Why don't you always use `infer_datetime_format = True?`** There are two big reasons not to always have pandas guess the time format. The first is that pandas won't always been able to figure out the correct date format, especially if someone has gotten creative with data entry. The second is that it's much slower than specifying the exact format of the dates.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "beba42ab-fb0e-4285-83cb-984a51bdb8ed",
    "_uuid": "c029d8021e0d6cd5de3c9e62014a498c7dd5d582"
   },
   "outputs": [],
   "source": [
    "# Your turn! Create a new column, date_parsed, in the earthquakes\n",
    "# dataset that has correctly parsed dates in it. (Don't forget to \n",
    "# double-check that the dtype is correct!)\n",
    "earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1965-01-02 00:00:00\n",
       "1    1965-01-04 00:00:00\n",
       "2    1965-01-05 00:00:00\n",
       "3    1965-01-08 00:00:00\n",
       "4    1965-01-09 00:00:00\n",
       "Name: date_parsed, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes['date_parsed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f310829-85bd-44c8-b1c5-d582407b5931",
    "_uuid": "3d6f5bef5deb1c1d4d83bbcaeb9ba23612978f35"
   },
   "source": [
    "# Select just the day of the month from our column\n",
    "___\n",
    "\n",
    "\"Ok, Rachael,\" you may be saying at this point, \"This messing around with data types is fine, I guess, but what's the *point*?\" To answer your question, let's try to get information on the day of the month that a landslide occured on from the original \"date\" column, which has an \"object\" dtype: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "ff451a5e-4447-40e2-ad76-367136a1fcff",
    "_uuid": "3c3be07dbf7394103a1db120e6ecbdffaf08d37f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-964a91f809fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# try to get the day of the month from the date column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mday_of_month_landslides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlandslides\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5268\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5269\u001b[0m         ):\n\u001b[1;32m-> 5270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# try to get the day of the month from the date column\n",
    "day_of_month_landslides = landslides['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c78aada6-c4d9-4464-894e-bdd4fabb4b13",
    "_uuid": "5847844cdd3aede3ff62bc5115f1d69c91b4af9d"
   },
   "source": [
    "We got an error! The important part to look at here is the part at the very end that says `AttributeError: Can only use .dt accessor with datetimelike values`. We're getting this error because the dt.day() function doesn't know how to deal with a column with the dtype \"object\". Even though our dataframe has dates in it, because they haven't been parsed we can't interact with them in a useful way.\n",
    "\n",
    "Luckily, we have a column that we parsed earlier , and that lets us get the day of the month out no problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "_cell_guid": "27b6422d-3a62-47ca-bb87-6e6292bed7cf",
    "_uuid": "e0be15da345949c990b5789e2a94f8f4e09e4cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2.0\n",
      "1       22.0\n",
      "2        6.0\n",
      "3       14.0\n",
      "4       15.0\n",
      "        ... \n",
      "1688     7.0\n",
      "1689    22.0\n",
      "1690    23.0\n",
      "1691    26.0\n",
      "1692     2.0\n",
      "Name: date_parsed, Length: 1693, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get the day of the month from the date_parsed column\n",
    "day_of_month_landslides = landslides['date_parsed'].dt.day\n",
    "print(day_of_month_landslides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1965-01-02 00:00:00\n",
      "1        1965-01-04 00:00:00\n",
      "2        1965-01-05 00:00:00\n",
      "3        1965-01-08 00:00:00\n",
      "4        1965-01-09 00:00:00\n",
      "                ...         \n",
      "23407    2016-12-28 00:00:00\n",
      "23408    2016-12-28 00:00:00\n",
      "23409    2016-12-28 00:00:00\n",
      "23410    2016-12-29 00:00:00\n",
      "23411    2016-12-30 00:00:00\n",
      "Name: date_parsed, Length: 23412, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get the day of the month from the date_parsed column for earthquakes\n",
    "day_of_month_earthquakes = earthquakes['date_parsed']\n",
    "print(day_of_month_earthquakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fe33df7d-c85d-4b61-b572-5682e6eea81b",
    "_uuid": "a2cec7b480ef13c070d40ca0e0763d2d30a86a9c"
   },
   "source": [
    "# Plot the day of the month to check the date parsing\n",
    "___\n",
    "\n",
    "One of the biggest dangers in parsing dates is mixing up the months and days. The to_datetime() function does have very helpful error messages, but it doesn't hurt to double-check that the days of the month we've extracted make sense. \n",
    "\n",
    "To do this, let's plot a histogram of the days of the month. We expect it to have values between 1 and 31 and, since there's no reason to suppose the landslides are more common on some days of the month than others, a relatively even distribution. (With a dip on 31 because not all months have 31 days.) Let's see if that's the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_cell_guid": "49feb18f-c077-474e-9353-a24ae850acf6",
    "_uuid": "d3d5a143d3d49e10187e420abfe9cfe18c7bac56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24f5281a748>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove na's\n",
    "day_of_month_landslides = day_of_month_landslides.dropna()\n",
    "\n",
    "# plot the day of the month\n",
    "sns.distplot(day_of_month_landslides, kde=False, bins=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8c706a4-2697-4520-b0dd-86fc6fb80326",
    "_uuid": "90016c3e93eb8499d9efe2ece32fb5b70dcbd2ae"
   },
   "source": [
    "Yep, it looks like we did parse our dates correctly & this graph makes good sense to me. Why don't you take a turn checking the dates you parsed earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_cell_guid": "7b5a7571-2ee3-4aad-94e9-ba47b06e6a29",
    "_uuid": "f2b79871c730f32f5ef1889912b7a8623eccf98f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-2dbd1ede9629>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# remove na's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mday_of_month_earthquakes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday_of_month_earthquakes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday_of_month_earthquakes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[1;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# Make a a 1-d float array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'datetime.datetime'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your turn! Plot the days of the month from your\n",
    "# earthquake dataset and make sure they make sense.\n",
    "# plot the day of the month\n",
    "# remove na's\n",
    "day_of_month_earthquakes = day_of_month_earthquakes.dropna()\n",
    "sns.distplot(day_of_month_earthquakes, kde=False, bins=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n",
    "\n",
    "Remember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also lets you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n",
    "\n",
    "# More practice!\n",
    "___\n",
    "\n",
    "If you're interested in graphing time series, [check out this Learn tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n",
    "\n",
    "You can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n",
    "\n",
    "For an extra challenge, you can try try parsing the column `Last Known Eruption` from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "dd64bc7c-c361-44d3-9f02-f7f8a2cb8430",
    "_uuid": "0027b29db32dc34294f713c345747a37d89cfd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764     Unknown\n",
       "1069    1996 CE\n",
       "34      1855 CE\n",
       "489     2016 CE\n",
       "9       1302 CE\n",
       "Name: Last Known Eruption, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volcanos['Last Known Eruption'].sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
