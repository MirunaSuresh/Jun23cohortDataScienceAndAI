{"cells":[{"metadata":{"_cell_guid":"b91a74ba-85f4-486e-b5f9-d0898f0626bf","_uuid":"6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"},"cell_type":"markdown","source":"### All days of the challange:\n\n* [Day 1: Handling missing values](https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values)\n* [Day 2: Scaling and normalization](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)\n* [Day 3: Parsing dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)\n* [Day 4: Character encodings](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/)\n* [Day 5: Inconsistent Data Entry](https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry/)\n___\nWelcome to day 3 of the 5-Day Data Challenge! Today, we're going to work with dates. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\nHere's what we're going to do today:\n\n* [Get our environment set up](#Get-our-environment-set-up)\n* [Check the data type of our date column](#Check-the-data-type-of-our-date-column)\n* [Convert our date columns to datetime](#Convert-our-date-columns-to-datetime)\n* [Select just the day of the month from our column](#Select-just-the-day-of-the-month-from-our-column)\n* [Plot the day of the month to check the date parsing](#Plot-the-day-of-the-month-to-the-date-parsing)\n\nLet's get started!"},{"metadata":{"_cell_guid":"5cd5061f-ae30-4837-a53b-690ffd5c5830","_uuid":"9d82bf13584b8e682962fbb96131f2447d741679"},"cell_type":"markdown","source":"# Get our environment set up\n________\n\nThe first thing we'll need to do is load in the libraries and datasets we'll be using. For today, we'll be working with two datasets: one containing information on earthquakes that occured between 1965 and 2016, and another that contains information on landslides that occured between 2007 and 2016.\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"},{"metadata":{"_cell_guid":"135a7804-b5f5-40aa-8657-4a15774e3666","_uuid":"835cbe0834b935fb0fd40c75b9c39454836f4d5f","trusted":true},"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport datetime\n\n# read in our data\nearthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\nlandslides = pd.read_csv(\"../input/landslide-events/catalog.csv\")\nvolcanos = pd.read_csv(\"../input/volcanic-eruptions/database.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"604ac3a4-b1d9-4264-b312-4bbeecdeec00","_uuid":"03ce3b4afe87d98f777172c2c7be066a66a0b237"},"cell_type":"markdown","source":"Now we're ready to look at some dates! (If you like, you can take this opportunity to take a look at some of the data.)"},{"metadata":{"_cell_guid":"9b87a77d-e5e5-4581-9cd3-0e7339fe1516","_uuid":"742028572a307a42ce40db0102171bc219b05282"},"cell_type":"markdown","source":"# Check the data type of our date column\n___\n\nFor this part of the challenge, I'll be working with the `date` column from the `landslides` dataframe. The very first thing I'm going to do is take a peek at the first few rows to make sure it actually looks like it contains dates."},{"metadata":{"_cell_guid":"e6b7eb39-c3e3-40a1-b0a5-91cfcd2d42da","_uuid":"93a08de7a6a621e4b07968c07c1cc612936c6027","trusted":true},"cell_type":"code","source":"# print the first few rows of the date column\nprint(landslides['date'].head())","execution_count":2,"outputs":[{"output_type":"stream","text":"0     3/2/07\n1    3/22/07\n2     4/6/07\n3    4/14/07\n4    4/15/07\nName: date, dtype: object\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dbdacb7c-10d4-4b0a-8f6b-6d4a940ca446","_uuid":"d88dbc08ab145fd20f86073b027c53f40fd306bc"},"cell_type":"markdown","source":"Yep, those are dates! But just because I, a human, can tell that these are dates doesn't mean that Python knows that they're dates. Notice that the at the bottom of the output of `head()`, you can see that it says that the data type of this  column is \"object\". \n\n> Pandas uses the \"object\" dtype for storing various types of data types, but most often when you see a column with the dtype \"object\" it will have strings in it. \n\nIf you check the pandas dtype documentation [here](http://pandas.pydata.org/pandas-docs/stable/basics.html#dtypes), you'll notice that there's also a specific `datetime64` dtypes. Because the dtype of our column is `object` rather than `datetime64`, we can tell that Python doesn't know that this column contains dates.\n\nWe can also look at just the dtype of your column without printing the first few rows if we like:"},{"metadata":{"_cell_guid":"56a047f4-cbf7-4914-951c-a04310ee7432","_uuid":"e2ab2ac80aaac7b165b3af64edb75d29f2612482","trusted":true},"cell_type":"code","source":"# check the data type of our date column\nlandslides['date'].dtype","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"dtype('O')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99a207db-3db0-4343-9805-58753f51f6e8","_uuid":"06e6483764014a04e7a1f34525e2f12aee5fdab8"},"cell_type":"markdown","source":"You may have to check the [numpy documentation](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind) to match the letter code to the dtype of the object. \"O\" is the code for \"object\", so we can see that these two methods give us the same information."},{"metadata":{"_cell_guid":"8987e921-0c37-4c0f-ba68-e4e26d8d1a1b","_uuid":"a2a983470b318469993b75b450bab28c12b59ae6","trusted":true},"cell_type":"code","source":"# Your turn! Check the data type of the Date column in the earthquakes dataframe\n# (note the capital 'D' in date!)\nearthquakes['Date'].dtype","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"dtype('O')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(earthquakes['Date'].head())","execution_count":16,"outputs":[{"output_type":"stream","text":"0    01/02/1965\n1    01/04/1965\n2    01/05/1965\n3    01/08/1965\n4    01/09/1965\nName: Date, dtype: object\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"earthquakes.head(10)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"         Date      Time  Latitude  Longitude        Type  Depth  Depth Error  \\\n0  01/02/1965  13:44:18    19.246    145.616  Earthquake  131.6          NaN   \n1  01/04/1965  11:29:49     1.863    127.352  Earthquake   80.0          NaN   \n2  01/05/1965  18:05:58   -20.579   -173.972  Earthquake   20.0          NaN   \n3  01/08/1965  18:49:43   -59.076    -23.557  Earthquake   15.0          NaN   \n4  01/09/1965  13:32:50    11.938    126.427  Earthquake   15.0          NaN   \n5  01/10/1965  13:36:32   -13.405    166.629  Earthquake   35.0          NaN   \n6  01/12/1965  13:32:25    27.357     87.867  Earthquake   20.0          NaN   \n7  01/15/1965  23:17:42   -13.309    166.212  Earthquake   35.0          NaN   \n8  01/16/1965  11:32:37   -56.452    -27.043  Earthquake   95.0          NaN   \n9  01/17/1965  10:43:17   -24.563    178.487  Earthquake  565.0          NaN   \n\n   Depth Seismic Stations  Magnitude Magnitude Type    ...      \\\n0                     NaN        6.0             MW    ...       \n1                     NaN        5.8             MW    ...       \n2                     NaN        6.2             MW    ...       \n3                     NaN        5.8             MW    ...       \n4                     NaN        5.8             MW    ...       \n5                     NaN        6.7             MW    ...       \n6                     NaN        5.9             MW    ...       \n7                     NaN        6.0             MW    ...       \n8                     NaN        6.0             MW    ...       \n9                     NaN        5.8             MW    ...       \n\n   Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n0                         NaN            NaN                  NaN   \n1                         NaN            NaN                  NaN   \n2                         NaN            NaN                  NaN   \n3                         NaN            NaN                  NaN   \n4                         NaN            NaN                  NaN   \n5                         NaN            NaN                  NaN   \n6                         NaN            NaN                  NaN   \n7                         NaN            NaN                  NaN   \n8                         NaN            NaN                  NaN   \n9                         NaN            NaN                  NaN   \n\n   Horizontal Error  Root Mean Square               ID     Source  \\\n0               NaN               NaN     ISCGEM860706     ISCGEM   \n1               NaN               NaN     ISCGEM860737     ISCGEM   \n2               NaN               NaN     ISCGEM860762     ISCGEM   \n3               NaN               NaN     ISCGEM860856     ISCGEM   \n4               NaN               NaN     ISCGEM860890     ISCGEM   \n5               NaN               NaN     ISCGEM860922     ISCGEM   \n6               NaN               NaN     ISCGEM861007     ISCGEM   \n7               NaN               NaN     ISCGEM861111     ISCGEM   \n8               NaN               NaN  ISCGEMSUP861125  ISCGEMSUP   \n9               NaN               NaN     ISCGEM861148     ISCGEM   \n\n  Location Source Magnitude Source     Status  \n0          ISCGEM           ISCGEM  Automatic  \n1          ISCGEM           ISCGEM  Automatic  \n2          ISCGEM           ISCGEM  Automatic  \n3          ISCGEM           ISCGEM  Automatic  \n4          ISCGEM           ISCGEM  Automatic  \n5          ISCGEM           ISCGEM  Automatic  \n6          ISCGEM           ISCGEM  Automatic  \n7          ISCGEM           ISCGEM  Automatic  \n8          ISCGEM           ISCGEM  Automatic  \n9          ISCGEM           ISCGEM  Automatic  \n\n[10 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/02/1965</td>\n      <td>13:44:18</td>\n      <td>19.246</td>\n      <td>145.616</td>\n      <td>Earthquake</td>\n      <td>131.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860706</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/04/1965</td>\n      <td>11:29:49</td>\n      <td>1.863</td>\n      <td>127.352</td>\n      <td>Earthquake</td>\n      <td>80.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860737</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/05/1965</td>\n      <td>18:05:58</td>\n      <td>-20.579</td>\n      <td>-173.972</td>\n      <td>Earthquake</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.2</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860762</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/08/1965</td>\n      <td>18:49:43</td>\n      <td>-59.076</td>\n      <td>-23.557</td>\n      <td>Earthquake</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860856</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/09/1965</td>\n      <td>13:32:50</td>\n      <td>11.938</td>\n      <td>126.427</td>\n      <td>Earthquake</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860890</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01/10/1965</td>\n      <td>13:36:32</td>\n      <td>-13.405</td>\n      <td>166.629</td>\n      <td>Earthquake</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.7</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM860922</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>01/12/1965</td>\n      <td>13:32:25</td>\n      <td>27.357</td>\n      <td>87.867</td>\n      <td>Earthquake</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.9</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861007</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>01/15/1965</td>\n      <td>23:17:42</td>\n      <td>-13.309</td>\n      <td>166.212</td>\n      <td>Earthquake</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861111</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01/16/1965</td>\n      <td>11:32:37</td>\n      <td>-56.452</td>\n      <td>-27.043</td>\n      <td>Earthquake</td>\n      <td>95.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEMSUP861125</td>\n      <td>ISCGEMSUP</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01/17/1965</td>\n      <td>10:43:17</td>\n      <td>-24.563</td>\n      <td>178.487</td>\n      <td>Earthquake</td>\n      <td>565.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.8</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ISCGEM861148</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>ISCGEM</td>\n      <td>Automatic</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"fb3b552b-411b-4fc0-b1e6-a3a8156fd459","_uuid":"0939ce269aef7001e35cc8f2a5f1eed1f6160940"},"cell_type":"markdown","source":"# Convert our date columns to datetime\n___\n\nNow that we know that our date column isn't being recognized as a date, it's time to convert it so that it *is* recognized as a date. This is called \"parsing dates\" because we're taking in a string and identifying its component parts.\n\nWe can pandas what the format of our dates are with a guide called as [\"strftime directive\", which you can find more information on at this link](http://strftime.org/). The basic idea is that you need to point out which parts of the date are where and what punctuation is between them. There are [lots of possible parts of a date](http://strftime.org/), but the most common are `%d` for day, `%m` for month, `%y` for a two-digit year and `%Y` for a four digit year.\n\nSome examples:\n\n * 1/17/07 has the format \"%m/%d/%y\"\n * 17-1-2007 has the format \"%d-%m-%Y\"\n \n Looking back up at the head of the `date` column in the landslides dataset, we can see that it's in the format \"month/day/two-digit year\", so we can use the same syntax as the first example to parse in our dates: "},{"metadata":{"_cell_guid":"f955aa17-ede7-4457-a913-ba1c44f8846d","_uuid":"a471aae50241b245caa0c60fbb19821372682b76","scrolled":false,"trusted":true},"cell_type":"code","source":"# create a new column, date_parsed, with the parsed dates\nlandslides['date_parsed'] = pd.to_datetime(landslides['date'], format = \"%m/%d/%y\")","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"09c1c55c-3883-4f5e-8ea9-e914b09416b6","_uuid":"50feaed5f874d8c09f983ad3172febdc54f4f0bb"},"cell_type":"markdown","source":"Now when I check the first few rows of the new column, I can see that the dtype is `datetime64`. I can also see that my dates have been slightly rearranged so that they fit the default order datetime objects (year-month-day)."},{"metadata":{"_cell_guid":"5a6c6244-b724-4a70-b356-6e3fb1e61270","_uuid":"2bff07787e5aa5ad2b6484c5bcee18b5b2f283bc","trusted":true},"cell_type":"code","source":"# print the first few rows\nlandslides['date_parsed'].head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"0   2007-03-02\n1   2007-03-22\n2   2007-04-06\n3   2007-04-14\n4   2007-04-15\nName: date_parsed, dtype: datetime64[ns]"},"metadata":{}}]},{"metadata":{"_cell_guid":"7bd8f8b6-8a60-4a12-b94b-4100188845da","_uuid":"fc95b22f0f4d7a6bc0cb1a7cc55abfb204cc81f9"},"cell_type":"markdown","source":"Now that our dates are parsed correctly, we can interact with them in useful ways.\n\n___\n* **What if I run into an error with multiple date formats?** While we're specifying the date format here, sometimes you'll run into an error when there are multiple date formats in a single column. If that happens, you have have pandas try to infer what the right date format should be. You can do that like so:\n\n`landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)`\n\n* **Why don't you always use `infer_datetime_format = True?`** There are two big reasons not to always have pandas guess the time format. The first is that pandas won't always been able to figure out the correct date format, especially if someone has gotten creative with data entry. The second is that it's much slower than specifying the exact format of the dates.\n____"},{"metadata":{"trusted":true},"cell_type":"code","source":"earthquakes['Date'].dtype","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"dtype('O')"},"metadata":{}}]},{"metadata":{"_cell_guid":"beba42ab-fb0e-4285-83cb-984a51bdb8ed","_uuid":"c029d8021e0d6cd5de3c9e62014a498c7dd5d582","trusted":true},"cell_type":"code","source":"# Your turn! Create a new column, date_parsed, in the earthquakes\n# dataset that has correctly parsed dates in it. (Don't forget to \n# double-check that the dtype is correct!)\nearthquakes['Date_parsed'] = pd.to_datetime(earthquakes['Date'], format = \"%m/%d/%Y\",errors=\"coerce\")\nearthquakes['Date_parsed']\n","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"0       1965-01-02\n1       1965-01-04\n2       1965-01-05\n3       1965-01-08\n4       1965-01-09\n5       1965-01-10\n6       1965-01-12\n7       1965-01-15\n8       1965-01-16\n9       1965-01-17\n10      1965-01-17\n11      1965-01-24\n12      1965-01-29\n13      1965-02-01\n14      1965-02-02\n15      1965-02-04\n16      1965-02-04\n17      1965-02-04\n18      1965-02-04\n19      1965-02-04\n20      1965-02-04\n21      1965-02-04\n22      1965-02-04\n23      1965-02-04\n24      1965-02-04\n25      1965-02-04\n26      1965-02-04\n27      1965-02-04\n28      1965-02-04\n29      1965-02-04\n           ...    \n23382   2016-12-11\n23383   2016-12-14\n23384   2016-12-14\n23385   2016-12-16\n23386   2016-12-17\n23387   2016-12-17\n23388   2016-12-17\n23389   2016-12-18\n23390   2016-12-18\n23391   2016-12-18\n23392   2016-12-18\n23393   2016-12-18\n23394   2016-12-18\n23395   2016-12-20\n23396   2016-12-20\n23397   2016-12-20\n23398   2016-12-20\n23399   2016-12-21\n23400   2016-12-21\n23401   2016-12-24\n23402   2016-12-24\n23403   2016-12-25\n23404   2016-12-25\n23405   2016-12-27\n23406   2016-12-28\n23407   2016-12-28\n23408   2016-12-28\n23409   2016-12-28\n23410   2016-12-29\n23411   2016-12-30\nName: Date_parsed, Length: 23412, dtype: datetime64[ns]"},"metadata":{}}]},{"metadata":{"_cell_guid":"9f310829-85bd-44c8-b1c5-d582407b5931","_uuid":"3d6f5bef5deb1c1d4d83bbcaeb9ba23612978f35"},"cell_type":"markdown","source":"# Select just the day of the month from our column\n___\n\n\"Ok, Rachael,\" you may be saying at this point, \"This messing around with data types is fine, I guess, but what's the *point*?\" To answer your question, let's try to get information on the day of the month that a landslide occured on from the original \"date\" column, which has an \"object\" dtype: "},{"metadata":{"_cell_guid":"ff451a5e-4447-40e2-ad76-367136a1fcff","_uuid":"3c3be07dbf7394103a1db120e6ecbdffaf08d37f","trusted":true},"cell_type":"code","source":"# try to get the day of the month from the date column\nday_of_month_landslides = landslides['date'].dt.day","execution_count":29,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"Can only use .dt accessor with datetimelike values","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m_make_accessor\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36mmaybe_to_datetimelike\u001b[0;34m(data, copy)\u001b[0m\n\u001b[1;32m     81\u001b[0m     raise TypeError(\"cannot convert an object of type {0} to a \"\n\u001b[0;32m---> 82\u001b[0;31m                     \"datetimelike index\".format(type(data)))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot convert an object of type <class 'pandas.core.series.Series'> to a datetimelike index","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-3d149a5c7336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try to get the day of the month from the date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mday_of_month_landslides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandslides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3608\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   3609\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 3610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m_make_accessor\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             raise AttributeError(\"Can only use .dt accessor with \"\n\u001b[0m\u001b[1;32m    259\u001b[0m                                  \"datetimelike values\")\n","\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"]}]},{"metadata":{"_cell_guid":"c78aada6-c4d9-4464-894e-bdd4fabb4b13","_uuid":"5847844cdd3aede3ff62bc5115f1d69c91b4af9d"},"cell_type":"markdown","source":"We got an error! The important part to look at here is the part at the very end that says `AttributeError: Can only use .dt accessor with datetimelike values`. We're getting this error because the dt.day() function doesn't know how to deal with a column with the dtype \"object\". Even though our dataframe has dates in it, because they haven't been parsed we can't interact with them in a useful way.\n\nLuckily, we have a column that we parsed earlier , and that lets us get the day of the month out no problem:"},{"metadata":{"_cell_guid":"27b6422d-3a62-47ca-bb87-6e6292bed7cf","_uuid":"e0be15da345949c990b5789e2a94f8f4e09e4cf5","trusted":true},"cell_type":"code","source":"# get the day of the month from the date_parsed column\nday_of_month_landslides = landslides['date_parsed'].dt.day\nday_of_month_landslides","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"0        2.0\n1       22.0\n2        6.0\n3       14.0\n4       15.0\n5       20.0\n6       24.0\n7       21.0\n8       27.0\n9       27.0\n10      27.0\n11       1.0\n12       4.0\n13       8.0\n14      13.0\n15      24.0\n16       9.0\n17      11.0\n18      14.0\n19      17.0\n20      18.0\n21      18.0\n22      18.0\n23      19.0\n24      19.0\n25      20.0\n26      21.0\n27      21.0\n28      23.0\n29       1.0\n        ... \n1663    17.0\n1664    10.0\n1665    31.0\n1666    31.0\n1667    22.0\n1668     9.0\n1669    23.0\n1670    21.0\n1671    21.0\n1672    12.0\n1673    15.0\n1674    24.0\n1675    24.0\n1676    15.0\n1677    24.0\n1678    21.0\n1679    24.0\n1680    28.0\n1681    24.0\n1682    27.0\n1683    27.0\n1684    14.0\n1685    26.0\n1686    27.0\n1687    29.0\n1688     7.0\n1689    22.0\n1690    23.0\n1691    26.0\n1692     2.0\nName: date_parsed, Length: 1693, dtype: float64"},"metadata":{}}]},{"metadata":{"_cell_guid":"aa3c05ea-f6d1-453f-86dc-c2fd9f8b3fd6","_uuid":"ffe9bfc0acef502b995aa61ee1c5d2e4a59a5e4e","trusted":true},"cell_type":"code","source":"# Your turn! get the day of the month from the date_parsed column\nday_of_month_earthquakes = earthquakes['Date_parsed'].dt.day\nday_of_month_earthquakes","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"0         2.0\n1         4.0\n2         5.0\n3         8.0\n4         9.0\n5        10.0\n6        12.0\n7        15.0\n8        16.0\n9        17.0\n10       17.0\n11       24.0\n12       29.0\n13        1.0\n14        2.0\n15        4.0\n16        4.0\n17        4.0\n18        4.0\n19        4.0\n20        4.0\n21        4.0\n22        4.0\n23        4.0\n24        4.0\n25        4.0\n26        4.0\n27        4.0\n28        4.0\n29        4.0\n         ... \n23382    11.0\n23383    14.0\n23384    14.0\n23385    16.0\n23386    17.0\n23387    17.0\n23388    17.0\n23389    18.0\n23390    18.0\n23391    18.0\n23392    18.0\n23393    18.0\n23394    18.0\n23395    20.0\n23396    20.0\n23397    20.0\n23398    20.0\n23399    21.0\n23400    21.0\n23401    24.0\n23402    24.0\n23403    25.0\n23404    25.0\n23405    27.0\n23406    28.0\n23407    28.0\n23408    28.0\n23409    28.0\n23410    29.0\n23411    30.0\nName: Date_parsed, Length: 23412, dtype: float64"},"metadata":{}}]},{"metadata":{"_cell_guid":"fe33df7d-c85d-4b61-b572-5682e6eea81b","_uuid":"a2cec7b480ef13c070d40ca0e0763d2d30a86a9c"},"cell_type":"markdown","source":"# Plot the day of the month to check the date parsing\n___\n\nOne of the biggest dangers in parsing dates is mixing up the months and days. The to_datetime() function does have very helpful error messages, but it doesn't hurt to double-check that the days of the month we've extracted make sense. \n\nTo do this, let's plot a histogram of the days of the month. We expect it to have values between 1 and 31 and, since there's no reason to suppose the landslides are more common on some days of the month than others, a relatively even distribution. (With a dip on 31 because not all months have 31 days.) Let's see if that's the case:"},{"metadata":{"_cell_guid":"49feb18f-c077-474e-9353-a24ae850acf6","_uuid":"d3d5a143d3d49e10187e420abfe9cfe18c7bac56","trusted":true},"cell_type":"code","source":"# remove na's\nday_of_month_landslides = day_of_month_landslides.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_landslides, kde=False, bins=31)","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f46ab999518>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f46ab999978>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAELCAYAAADJF31HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuiR1wkCXpE78P4H3LsG2jBn0AAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"metadata":{"_cell_guid":"c8c706a4-2697-4520-b0dd-86fc6fb80326","_uuid":"90016c3e93eb8499d9efe2ece32fb5b70dcbd2ae"},"cell_type":"markdown","source":"Yep, it looks like we did parse our dates correctly & this graph makes good sense to me. Why don't you take a turn checking the dates you parsed earlier?"},{"metadata":{"_cell_guid":"7b5a7571-2ee3-4aad-94e9-ba47b06e6a29","_uuid":"f2b79871c730f32f5ef1889912b7a8623eccf98f","trusted":true},"cell_type":"code","source":"# Your turn! Plot the days of the month from your\n# earthquake dataset and make sure they make sense.\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde=True, bins=31)","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f46ab92cc18>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f46ab8f6c88>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAET1JREFUeJzt3X2s5FV9x/H3RxYEUVkeFkKWpYt1\n24qKQlakag0RNQWNS1uxig9bS7KmQUWpUappsW2aaGuLGlvMKupaUUDAQhqiUh7iQ+rC8uAibC1b\nRFihsIYHRUULfPvHnFtul7t7Z9l7mZmz71dyc3+/M+c3c8793fuZc8/85kyqCklSv5406gZIkuaX\nQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknq3IJRNwBgv/32q6VLl466GZI0Ua65\n5pofV9Wi2eqNRdAvXbqUdevWjboZkjRRkvxwmHpO3UhS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TO\nGfSS1DmDXpI6Z9BLUufG4p2xmnxfXHvbUPVOfOHB89wSSVtyRC9JnTPoJalzBr0kdc6gl6TOGfSS\n1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzrmombSdXMBNk8YRvSR1zhG9pK3yv5c+\nOKKXpM4Z9JLUOadupAnhNIoeL0f0ktS5oYI+ybuT3Jjke0m+lGT3JIckWZvk5iTnJtmt1X1y29/Y\nbl86nx2QJG3brEGfZDHwTmB5VT0H2AV4PfBh4IyqWgbcC5zUDjkJuLeqngmc0epJkkZk2Dn6BcAe\nSf4HeApwJ/Ay4MR2+xrgg8CZwIq2DXA+8IkkqaqaozZL82bYeXBpkswa9FX1oyQfAW4DfgF8HbgG\nuK+qHmrVNgGL2/Zi4PZ27ENJ7gf2BX48x22XfIFSGsKsQZ9kbwaj9EOA+4AvA8fOUHVqxJ5t3Db9\nflcBqwAOPtg/QkmPmssncAcDw03dvBz4QVVtBkhyIfAiYGGSBW1UfxBwR6u/CVgCbEqyANgLuGfL\nO62q1cBqgOXLlzuts5Pwj0564g1z1c1twFFJnpIkwDHATcAVwGtbnZXARW374rZPu/1y5+claXRm\nDfqqWsvgRdVrgRvaMauB9wGnJtnIYA7+rHbIWcC+rfxU4LR5aLckaUhDXXVTVacDp29RfAtw5Ax1\nHwRO2PGmjcY4Ty2Mc9skjS+XQJA6M8yAwMHAzmXig95RroYxiuvj/d3UuJj4oB93jq4kjZpBr1mN\n82i4B/ZV882gl7TDDPDx5jLFktQ5g16SOufUzRjw315J88kRvSR1zqCXpM45dfM4jfN0i2/UkTSd\nI3pJ6pxBL0mdM+glqXMGvSR1zhdjd2Lj/IKyNAx/h4ez0wS9vxCSdlY7TdBLepQDn52Lc/SS1DmD\nXpI6Z9BLUucMeknqnEEvSZ3zqhtJou/FAA16SdoOk/iE4NSNJHXOoJekzhn0ktQ5g16SOmfQS1Ln\nDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjo3VNAnWZjk/CT/kWRDkt9Osk+SS5Pc3L7v\n3eomyceTbEyyPskR89sFSdK2DDui/xjw1ar6LeB5wAbgNOCyqloGXNb2AY4FlrWvVcCZc9piSdJ2\nmTXokzwdeClwFkBV/aqq7gNWAGtatTXA8W17BfD5GvgOsDDJgXPecknSUIYZ0T8D2Ax8Nsl1ST6d\nZE/ggKq6E6B937/VXwzcPu34Ta1MkjQCwwT9AuAI4MyqOhz4GY9O08wkM5TVYyolq5KsS7Ju8+bN\nQzVWkrT9hgn6TcCmqlrb9s9nEPx3TU3JtO93T6u/ZNrxBwF3bHmnVbW6qpZX1fJFixY93vZLkmYx\na9BX1X8Dtyf5zVZ0DHATcDGwspWtBC5q2xcDb2lX3xwF3D81xSNJeuIN+5mx7wDOTrIbcAvwVgZP\nEuclOQm4DTih1b0EOA7YCPy81ZUkjchQQV9V1wPLZ7jpmBnqFnDyDrZLkjRHfGesJHXOoJekzhn0\nktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9J\nnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5\ng16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS54YO+iS7JLkuyb+2\n/UOSrE1yc5Jzk+zWyp/c9je225fOT9MlScPYnhH9KcCGafsfBs6oqmXAvcBJrfwk4N6qeiZwRqsn\nSRqRoYI+yUHAq4BPt/0ALwPOb1XWAMe37RVtn3b7Ma2+JGkEhh3RfxR4L/BI298XuK+qHmr7m4DF\nbXsxcDtAu/3+Vv//SbIqybok6zZv3vw4my9Jms2sQZ/k1cDdVXXN9OIZqtYQtz1aULW6qpZX1fJF\nixYN1VhJ0vZbMESdFwOvSXIcsDvwdAYj/IVJFrRR+0HAHa3+JmAJsCnJAmAv4J45b7kkaSizjuir\n6s+q6qCqWgq8Hri8qt4IXAG8tlVbCVzUti9u+7TbL6+qx4zoJUlPjB25jv59wKlJNjKYgz+rlZ8F\n7NvKTwVO27EmSpJ2xDBTN/+nqq4ErmzbtwBHzlDnQeCEOWibJGkO+M5YSeqcQS9JnTPoJalzBr0k\ndc6gl6TOGfSS1DmDXpI6t13X0UuShvPFtbcNVe/EFx48zy1xRC9J3TPoJalzBr0kdc6gl6TOGfSS\n1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0md\nM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOzRr0SZYk\nuSLJhiQ3Jjmlle+T5NIkN7fve7fyJPl4ko1J1ic5Yr47IUnaumFG9A8Bf1pVzwKOAk5OcihwGnBZ\nVS0DLmv7AMcCy9rXKuDMOW+1JGloswZ9Vd1ZVde27Z8CG4DFwApgTau2Bji+ba8APl8D3wEWJjlw\nzlsuSRrKds3RJ1kKHA6sBQ6oqjth8GQA7N+qLQZun3bYplYmSRqBoYM+yVOBC4B3VdVPtlV1hrKa\n4f5WJVmXZN3mzZuHbYYkaTsNFfRJdmUQ8mdX1YWt+K6pKZn2/e5WvglYMu3wg4A7trzPqlpdVcur\navmiRYseb/slSbMY5qqbAGcBG6rqH6bddDGwsm2vBC6aVv6WdvXNUcD9U1M8kqQn3oIh6rwYeDNw\nQ5LrW9n7gQ8B5yU5CbgNOKHddglwHLAR+Dnw1jltsSRpu8wa9FX1LWaedwc4Zob6BZy8g+2SJM0R\n3xkrSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z\n9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEv\nSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLU\nuXkJ+iS/m+T7STYmOW0+HkOSNJw5D/okuwD/CBwLHAq8Icmhc/04kqThzMeI/khgY1XdUlW/As4B\nVszD40iShjAfQb8YuH3a/qZWJkkagQXzcJ+ZoaweUylZBaxquw8k+f4WVfYDfjzHbRsV+zJ+eukH\n2JdxNVRf3rhjj/Frw1Saj6DfBCyZtn8QcMeWlapqNbB6a3eSZF1VLZ/75j3x7Mv46aUfYF/G1Tj1\nZT6mbq4GliU5JMluwOuBi+fhcSRJQ5jzEX1VPZTk7cDXgF2Az1TVjXP9OJKk4czH1A1VdQlwyQ7e\nzVandSaQfRk/vfQD7Mu4Gpu+pOoxr5NKkjriEgiS1LmxDPpellBIcmuSG5Jcn2TdqNuzPZJ8Jsnd\nSb43rWyfJJcmubl933uUbRzWVvrywSQ/aufm+iTHjbKNw0iyJMkVSTYkuTHJKa184s7LNvoyiedl\n9yRXJflu68tftvJDkqxt5+XcdnHKaNo4blM3bQmF/wReweBSzauBN1TVTSNt2OOQ5FZgeVVN3HXB\nSV4KPAB8vqqe08r+Frinqj7UnoD3rqr3jbKdw9hKXz4IPFBVHxll27ZHkgOBA6vq2iRPA64Bjgf+\niAk7L9voy+uYvPMSYM+qeiDJrsC3gFOAU4ELq+qcJJ8EvltVZ46ijeM4oncJhTFQVd8A7tmieAWw\npm2vYfCHOfa20peJU1V3VtW1bfunwAYG7zqfuPOyjb5MnBp4oO3u2r4KeBlwfisf6XkZx6DvaQmF\nAr6e5Jr2TuBJd0BV3QmDP1Rg/xG3Z0e9Pcn6NrUz9tMd0yVZChwOrGXCz8sWfYEJPC9JdklyPXA3\ncCnwX8B9VfVQqzLSHBvHoB9qCYUJ8eKqOoLBSp4ntykEjYczgV8Hng/cCfz9aJszvCRPBS4A3lVV\nPxl1e3bEDH2ZyPNSVQ9X1fMZrARwJPCsmao9sa161DgG/VBLKEyCqrqjfb8b+AqDX4BJdlebW52a\nY717xO153KrqrvbH+QjwKSbk3LQ54AuAs6vqwlY8kedlpr5M6nmZUlX3AVcCRwELk0y9V2mkOTaO\nQd/FEgpJ9mwvMpFkT+CVwPe2fdTYuxhY2bZXAheNsC07ZCoYm99jAs5Ne9HvLGBDVf3DtJsm7rxs\nrS8Tel4WJVnYtvcAXs7gNYcrgNe2aiM9L2N31Q1Au6Tqozy6hMLfjLhJ2y3JMxiM4mHwDuQvTlI/\nknwJOJrBCnx3AacD/wKcBxwM3AacUFVj/yLnVvpyNIPpgQJuBd42Nc89rpK8BPgmcAPwSCt+P4O5\n7Yk6L9voyxuYvPNyGIMXW3dhMHg+r6r+qmXAOcA+wHXAm6rqlyNp4zgGvSRp7ozj1I0kaQ4Z9JLU\nOYNekjpn0EtS5wx6SeqcQS9JnTPoNRGSPNyWrb2xLQd7apJt/v4mWZrkxCeqjXMpyZVJxuKDpTX5\nDHpNil9U1fOr6tkMlrA+jsEbn7ZlKTCSoG/LbUtjwaDXxGlrB61isMph2sj9m0mubV8valU/BPxO\n+0/g3W2Fwb9LcnVbHfFtW3uMJEcn+UaSryS5Kcknp/6DSHJmknXTP2Sild+a5C+SfAs4Ick727Hr\nk5zT6uzZVmW8Osl1SVa08j2SnNPqngvsMT8/Pe2M5uXDwaX5VlW3tODdn8EiXq+oqgeTLAO+BCwH\nTgPeU1WvBmhLRd9fVS9I8mTg20m+XlU/2MrDHAkcCvwQ+Crw+wzWF/9AVd3TRu2XJTmsqta3Yx6s\nqpe0x7sDOKSqfjm1FgrwAeDyqvrjVnZVkn8D3gb8vKoOa2+pv3bOflja6Tmi1ySbWtJ6V+BTSW4A\nvswgnGfySuAtbd3wtcC+wLJt3P9V7QNwHmbw5PGSVv66JNcyWL/k2Vs83rnTttcDZyd5EzC1Lvkr\ngdNaG64EdmewRs1LgS8AtCeN9UhzxBG9JlJbMOphBqP50xksVvY8BoOXB7d2GPCOqvrakA+z5UJQ\nleQQ4D3AC6rq3iSfYxDWU342bftVDAL8NcCfJ3l2a8MfVNX3t+jPTI8nzQlH9Jo4SRYBnwQ+UYNV\n+fYC7mxrmL+ZwSqCAD8Fnjbt0K8Bf9LWQSfJb7QlpLfmyLZc9pOAP2TwWaBPZxDm9yc5gMGHyszU\nxicBS6rqCuC9wELgqa0N72jL9JLk8HbIN4A3trLnAIcN+/OQZuOIXpNijzbdsSuDaZB/BqbWMf8n\n4IIkJzBYA3xqVL0eeCjJd4HPAR9jcCXOtS1oN7Ptz/H8dwYv6D6XQRB/paoeSXIdcCNwC/DtrRy7\nC/CFJHsxGMWfUVX3JflrBktwr29tuBV4NYNPVvpskvXA9cBVQ/5cpFm5TLE0gyRHM+2FXGmSOXUj\nSZ1zRK+dWpLnMpgGmu6XVfXCUbRHmg8GvSR1zqkbSeqcQS9JnTPoJalzBr0kdc6gl6TO/S9joN66\ny77ltwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"metadata":{"_cell_guid":"b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee","_uuid":"52b0af56e3c77db96056e9acd785f8f435f7caf5"},"cell_type":"markdown","source":"And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also lets you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nIf you're interested in graphing time series, [check out this Learn tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n\nYou can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n\nFor an extra challenge, you can try try parsing the column `Last Known Eruption` from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD)."},{"metadata":{"_cell_guid":"dd64bc7c-c361-44d3-9f02-f7f8a2cb8430","_uuid":"0027b29db32dc34294f713c345747a37d89cfd26","collapsed":true,"trusted":false},"cell_type":"code","source":"volcanos['Last Known Eruption'].sample(5)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":1}