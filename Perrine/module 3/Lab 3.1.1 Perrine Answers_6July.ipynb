{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PopLE1ywNQsa"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e45O_NedNQsd"
   },
   "source": [
    "# Lab 3.1.1 \n",
    "# *Data Wrangling and Munging with Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr08YR1PNQsf"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH9yA6LINQsh"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baKB6_WIBp_8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8G9iecYNQsr"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MC0XSmScBqAD",
    "outputId": "c6f51e70-1f8e-412c-b320-b370e38f2a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Numpy: ', '1.16.5')\n",
      "('Pandas: ', u'0.24.2')\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzTKAG1LNQsx"
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE2wYKPNNQsy"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "()\n",
      "  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,0,3,13,16\n",
      "0  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "1  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "2  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "3  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "4  6,2011-01-01,1,0,1,5,0,6,0,2,0.24,0.2576,0.75,...     \n",
      "()\n",
      "  instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "0  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...                                                                   \n",
      "1  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "2  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "3  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n",
      "4  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "C:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  import sys\n",
      "C:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = None)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSiMJN9NNQs4"
   },
   "source": [
    "?:\n",
    "ANSWER: Case 1 treats headings as just another data row. Case 2 treats the 1st data row as the column header. Case 3 gets the header right (row 0), but reads each row as a single column (Nb. the other two make that same mistake). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDFYVoPINQs6"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wH2wuPznNQs8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 0, sep = ',')\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEwczD29NQtA"
   },
   "source": [
    "Note that we could have used `read.csv()` above. When is `read_table()` necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OsmNWLXNQtB"
   },
   "source": [
    "?:\n",
    "ANSWER: When `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPEoeHGGNQtC"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects \n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be delth with by correctly specifying the parameters of the function you use to load the file. Read the doco before reading the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0G5PtA2NQtC"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYELgCw6NQtD"
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile  # Nb. Need to install xlrd from conda (it does not automatically install with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDjzKP6nNQtF",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species_No</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species_No  Petal_width  Petal_length  Sepal_width  Sepal_length  \\\n",
       "0             1          0.2           1.4          3.5           5.1   \n",
       "1             1          0.2           1.4          3.0           4.9   \n",
       "2             1          0.2           1.3          3.2           4.7   \n",
       "3             1          0.2           1.5          3.1           4.6   \n",
       "4             1          0.2           1.4          3.6           5.0   \n",
       "5             1          0.4           1.7          3.9           5.4   \n",
       "6             1          0.3           1.4          3.4           4.6   \n",
       "7             1          0.2           1.5          3.4           5.0   \n",
       "8             1          0.2           1.4          2.9           4.4   \n",
       "9             1          0.1           1.5          3.1           4.9   \n",
       "10            1          0.2           1.5          3.7           5.4   \n",
       "11            1          0.2           1.6          3.4           4.8   \n",
       "12            1          0.1           1.4          3.0           4.8   \n",
       "13            1          0.1           1.1          3.0           4.3   \n",
       "14            1          0.2           1.2          4.0           5.8   \n",
       "15            1          0.4           1.5          4.4           5.7   \n",
       "16            1          0.4           1.3          3.9           5.4   \n",
       "17            1          0.3           1.4          3.5           5.1   \n",
       "18            1          0.3           1.7          3.8           5.7   \n",
       "19            1          0.3           1.5          3.8           5.1   \n",
       "20            1          0.2           1.7          3.4           5.4   \n",
       "21            1          0.4           1.5          3.7           5.1   \n",
       "22            1          0.2           1.0          3.6           4.6   \n",
       "23            1          0.5           1.7          3.3           5.1   \n",
       "24            1          0.2           1.9          3.4           4.8   \n",
       "25            1          0.2           1.6          3.0           5.0   \n",
       "26            1          0.4           1.6          3.4           5.0   \n",
       "27            1          0.2           1.5          3.5           5.2   \n",
       "28            1          0.2           1.4          3.4           5.2   \n",
       "29            1          0.2           1.6          3.2           4.7   \n",
       "..          ...          ...           ...          ...           ...   \n",
       "120           3          2.3           5.7          3.2           6.9   \n",
       "121           3          2.0           4.9          2.8           5.6   \n",
       "122           3          2.0           6.7          2.8           7.7   \n",
       "123           3          1.8           4.9          2.7           6.3   \n",
       "124           3          2.1           5.7          3.3           6.7   \n",
       "125           3          1.8           6.0          3.2           7.2   \n",
       "126           3          1.8           4.8          2.8           6.2   \n",
       "127           3          1.8           4.9          3.0           6.1   \n",
       "128           3          2.1           5.6          2.8           6.4   \n",
       "129           3          1.6           5.8          3.0           7.2   \n",
       "130           3          1.9           6.1          2.8           7.4   \n",
       "131           3          2.0           6.4          3.8           7.9   \n",
       "132           3          2.2           5.6          2.8           6.4   \n",
       "133           3          1.5           5.1          2.8           6.3   \n",
       "134           3          1.4           5.6          2.6           6.1   \n",
       "135           3          2.3           6.1          3.0           7.7   \n",
       "136           3          2.4           5.6          3.4           6.3   \n",
       "137           3          1.8           5.5          3.1           6.4   \n",
       "138           3          1.8           4.8          3.0           6.0   \n",
       "139           3          2.1           5.4          3.1           6.9   \n",
       "140           3          2.4           5.6          3.1           6.7   \n",
       "141           3          2.3           5.1          3.1           6.9   \n",
       "142           3          1.9           5.1          2.7           5.8   \n",
       "143           3          2.3           5.9          3.2           6.8   \n",
       "144           3          2.5           5.7          3.3           6.7   \n",
       "145           3          2.3           5.2          3.0           6.7   \n",
       "146           3          1.9           5.0          2.5           6.3   \n",
       "147           3          2.0           5.2          3.0           6.5   \n",
       "148           3          2.3           5.4          3.4           6.2   \n",
       "149           3          1.8           5.1          3.0           5.9   \n",
       "\n",
       "    Species_name  \n",
       "0         Setosa  \n",
       "1         Setosa  \n",
       "2         Setosa  \n",
       "3         Setosa  \n",
       "4         Setosa  \n",
       "5         Setosa  \n",
       "6         Setosa  \n",
       "7         Setosa  \n",
       "8         Setosa  \n",
       "9         Setosa  \n",
       "10        Setosa  \n",
       "11        Setosa  \n",
       "12        Setosa  \n",
       "13        Setosa  \n",
       "14        Setosa  \n",
       "15        Setosa  \n",
       "16        Setosa  \n",
       "17        Setosa  \n",
       "18        Setosa  \n",
       "19        Setosa  \n",
       "20        Setosa  \n",
       "21        Setosa  \n",
       "22        Setosa  \n",
       "23        Setosa  \n",
       "24        Setosa  \n",
       "25        Setosa  \n",
       "26        Setosa  \n",
       "27        Setosa  \n",
       "28        Setosa  \n",
       "29        Setosa  \n",
       "..           ...  \n",
       "120    Verginica  \n",
       "121    Verginica  \n",
       "122    Verginica  \n",
       "123    Verginica  \n",
       "124    Verginica  \n",
       "125    Verginica  \n",
       "126    Verginica  \n",
       "127    Verginica  \n",
       "128    Verginica  \n",
       "129    Verginica  \n",
       "130    Verginica  \n",
       "131    Verginica  \n",
       "132    Verginica  \n",
       "133    Verginica  \n",
       "134    Verginica  \n",
       "135    Verginica  \n",
       "136    Verginica  \n",
       "137    Verginica  \n",
       "138    Verginica  \n",
       "139    Verginica  \n",
       "140    Verginica  \n",
       "141    Verginica  \n",
       "142    Verginica  \n",
       "143    Verginica  \n",
       "144    Verginica  \n",
       "145    Verginica  \n",
       "146    Verginica  \n",
       "147    Verginica  \n",
       "148    Verginica  \n",
       "149    Verginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Iris.xls', sheet_name = 'Data')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0a2XhAZNQtH"
   },
   "source": [
    "So, this file appears to have an embedded table of aggregates on the same sheet as the raw data (a naughty but common practice amongst analysts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjWx-Xo0NQtH"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For ecxample, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tC5kzTsMNQtI"
   },
   "source": [
    "Load the above file without the unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P70uSXsNQtI",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Petal_width  Petal_length  Sepal_width  Sepal_length Species_name\n",
       "Species_No                                                                   \n",
       "1                   0.2           1.4          3.5           5.1       Setosa\n",
       "1                   0.2           1.4          3.0           4.9       Setosa\n",
       "1                   0.2           1.3          3.2           4.7       Setosa\n",
       "1                   0.2           1.5          3.1           4.6       Setosa\n",
       "1                   0.2           1.4          3.6           5.0       Setosa\n",
       "1                   0.4           1.7          3.9           5.4       Setosa\n",
       "1                   0.3           1.4          3.4           4.6       Setosa\n",
       "1                   0.2           1.5          3.4           5.0       Setosa\n",
       "1                   0.2           1.4          2.9           4.4       Setosa\n",
       "1                   0.1           1.5          3.1           4.9       Setosa\n",
       "1                   0.2           1.5          3.7           5.4       Setosa\n",
       "1                   0.2           1.6          3.4           4.8       Setosa\n",
       "1                   0.1           1.4          3.0           4.8       Setosa\n",
       "1                   0.1           1.1          3.0           4.3       Setosa\n",
       "1                   0.2           1.2          4.0           5.8       Setosa\n",
       "1                   0.4           1.5          4.4           5.7       Setosa\n",
       "1                   0.4           1.3          3.9           5.4       Setosa\n",
       "1                   0.3           1.4          3.5           5.1       Setosa\n",
       "1                   0.3           1.7          3.8           5.7       Setosa\n",
       "1                   0.3           1.5          3.8           5.1       Setosa"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "df = pd.read_excel('Iris.xls', sheet_name = 'Data', header = 0, nrows = 20, index_col = 'Species_No', usecols = [0,1,2,3,4,5])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTkOz1KsNQtK"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFHi_S4fNQtK"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS7P3oXQNQtL"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-hzkxRRNQtL"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFuaZ82hNQtM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-05T09:39:47.375Z</td>\n",
       "      <td>9.8744</td>\n",
       "      <td>-84.3523</td>\n",
       "      <td>10</td>\n",
       "      <td>4.30</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-05T10:13:29.176Z</td>\n",
       "      <td>5 km NW of Santiago, Costa Rica</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.075</td>\n",
       "      <td>50</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-05T09:21:27.320Z</td>\n",
       "      <td>17.9395</td>\n",
       "      <td>-66.9575</td>\n",
       "      <td>7</td>\n",
       "      <td>2.98</td>\n",
       "      <td>md</td>\n",
       "      <td>23.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-05T09:57:03.191Z</td>\n",
       "      <td>6 km SW of Guánica, Puerto Rico</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.080</td>\n",
       "      <td>5</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>pr</td>\n",
       "      <td>pr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude  longitude  depth   mag magType   nst  \\\n",
       "0  2020-07-05T09:39:47.375Z    9.8744   -84.3523     10  4.30      mb   NaN   \n",
       "1  2020-07-05T09:21:27.320Z   17.9395   -66.9575      7  2.98      md  23.0   \n",
       "\n",
       "   gap   dmin   rms  ...                   updated  \\\n",
       "0  154  0.269  1.13  ...  2020-07-05T10:13:29.176Z   \n",
       "1  202  0.086  0.13  ...  2020-07-05T09:57:03.191Z   \n",
       "\n",
       "                             place        type horizontalError depthError  \\\n",
       "0  5 km NW of Santiago, Costa Rica  earthquake            6.30       2.00   \n",
       "1  6 km SW of Guánica, Puerto Rico  earthquake            0.42       0.23   \n",
       "\n",
       "   magError  magNst    status  locationSource magSource  \n",
       "0     0.075      50  reviewed              us        us  \n",
       "1     0.080       5  reviewed              pr        pr  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGgcXCzyNQtN"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4oVabZ6NQtO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                             Bank Name                City  \\\n",
       " 0                                 The First State Bank       Barboursville   \n",
       " 1                                   Ericson State Bank             Ericson   \n",
       " 2                     City National Bank of New Jersey              Newark   \n",
       " 3                                        Resolute Bank              Maumee   \n",
       " 4                                Louisa Community Bank              Louisa   \n",
       " 5                                 The Enloe State Bank              Cooper   \n",
       " 6                  Washington Federal Bank for Savings             Chicago   \n",
       " 7      The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       " 8                                  Fayette County Bank          Saint Elmo   \n",
       " 9    Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       " 10                                      First NBC Bank         New Orleans   \n",
       " 11                                       Proficio Bank  Cottonwood Heights   \n",
       " 12                       Seaway Bank and Trust Company             Chicago   \n",
       " 13                              Harvest Community Bank          Pennsville   \n",
       " 14                                         Allied Bank            Mulberry   \n",
       " 15                        The Woodbury Banking Company            Woodbury   \n",
       " 16                              First CornerStone Bank     King of Prussia   \n",
       " 17                                  Trust Company Bank             Memphis   \n",
       " 18                          North Milwaukee State Bank           Milwaukee   \n",
       " 19                              Hometown National Bank            Longview   \n",
       " 20                                 The Bank of Georgia      Peachtree City   \n",
       " 21                                        Premier Bank              Denver   \n",
       " 22                                      Edgebrook Bank             Chicago   \n",
       " 23                              Doral Bank  En Español            San Juan   \n",
       " 24                   Capitol City Bank & Trust Company             Atlanta   \n",
       " 25                             Highland Community Bank             Chicago   \n",
       " 26                    First National Bank of Crestview           Crestview   \n",
       " 27                                  Northern Star Bank             Mankato   \n",
       " 28              Frontier Bank, FSB D/B/A El Paseo Bank         Palm Desert   \n",
       " 29               The National Republic Bank of Chicago             Chicago   \n",
       " ..                                                 ...                 ...   \n",
       " 531                                  ANB Financial, NA         Bentonville   \n",
       " 532                                          Hume Bank                Hume   \n",
       " 533                             Douglass National Bank         Kansas City   \n",
       " 534                                  Miami Valley Bank            Lakeview   \n",
       " 535                                            NetBank          Alpharetta   \n",
       " 536                          Metropolitan Savings Bank          Pittsburgh   \n",
       " 537                                    Bank of Ephraim             Ephraim   \n",
       " 538                                      Reliance Bank        White Plains   \n",
       " 539              Guaranty National Bank of Tallahassee         Tallahassee   \n",
       " 540                                Dollar Savings Bank              Newark   \n",
       " 541                               Pulaski Savings Bank        Philadelphia   \n",
       " 542              First National Bank of Blanchardville      Blanchardville   \n",
       " 543                              Southern Pacific Bank            Torrance   \n",
       " 544                        Farmers Bank of Cheneyville         Cheneyville   \n",
       " 545                                      Bank of Alamo               Alamo   \n",
       " 546             AmTrade International Bank  En Español             Atlanta   \n",
       " 547                     Universal Federal Savings Bank             Chicago   \n",
       " 548                       Connecticut Bank of Commerce            Stamford   \n",
       " 549                                   New Century Bank     Shelby Township   \n",
       " 550                              Net 1st National Bank          Boca Raton   \n",
       " 551                                       NextBank, NA             Phoenix   \n",
       " 552                           Oakwood Deposit Bank Co.             Oakwood   \n",
       " 553                              Bank of Sierra Blanca       Sierra Blanca   \n",
       " 554                      Hamilton Bank, NA  En Español               Miami   \n",
       " 555                             Sinclair National Bank            Gravette   \n",
       " 556                                 Superior Bank, FSB            Hinsdale   \n",
       " 557                                Malta National Bank               Malta   \n",
       " 558                    First Alliance Bank & Trust Co.          Manchester   \n",
       " 559                  National State Bank of Metropolis          Metropolis   \n",
       " 560                                   Bank of Honolulu            Honolulu   \n",
       " \n",
       "      ST   CERT                Acquiring Institution        Closing Date  \n",
       " 0    WV  14361                       MVB Bank, Inc.       April 3, 2020  \n",
       " 1    NE  18265           Farmers and Merchants Bank   February 14, 2020  \n",
       " 2    NJ  21111                      Industrial Bank    November 1, 2019  \n",
       " 3    OH  58317                   Buckeye State Bank    October 25, 2019  \n",
       " 4    KY  58112    Kentucky Farmers Bank Corporation    October 25, 2019  \n",
       " 5    TX  10716                   Legend Bank, N. A.        May 31, 2019  \n",
       " 6    IL  30570                   Royal Savings Bank   December 15, 2017  \n",
       " 7    KS  17719                          Conway Bank    October 13, 2017  \n",
       " 8    IL   1802            United Fidelity Bank, fsb        May 26, 2017  \n",
       " 9    WI  30003  First-Citizens Bank & Trust Company         May 5, 2017  \n",
       " 10   LA  58302                         Whitney Bank      April 28, 2017  \n",
       " 11   UT  35495                    Cache Valley Bank       March 3, 2017  \n",
       " 12   IL  19328                  State Bank of Texas    January 27, 2017  \n",
       " 13   NJ  34951  First-Citizens Bank & Trust Company    January 13, 2017  \n",
       " 14   AR     91                         Today's Bank  September 23, 2016  \n",
       " 15   GA  11297                          United Bank     August 19, 2016  \n",
       " 16   PA  35312  First-Citizens Bank & Trust Company         May 6, 2016  \n",
       " 17   TN   9956           The Bank of Fayette County      April 29, 2016  \n",
       " 18   WI  20364  First-Citizens Bank & Trust Company      March 11, 2016  \n",
       " 19   WA  35156                       Twin City Bank     October 2, 2015  \n",
       " 20   GA  35259                        Fidelity Bank     October 2, 2015  \n",
       " 21   CO  34112            United Fidelity Bank, fsb       July 10, 2015  \n",
       " 22   IL  57772             Republic Bank of Chicago         May 8, 2015  \n",
       " 23   PR  32102         Banco Popular de Puerto Rico   February 27, 2015  \n",
       " 24   GA  33938  First-Citizens Bank & Trust Company   February 13, 2015  \n",
       " 25   IL  20290            United Fidelity Bank, fsb    January 23, 2015  \n",
       " 26   FL  17557                       First NBC Bank    January 16, 2015  \n",
       " 27   MN  34983                            BankVista   December 19, 2014  \n",
       " 28   CA  34738    Bank of Southern California, N.A.    November 7, 2014  \n",
       " 29   IL    916                  State Bank of Texas    October 24, 2014  \n",
       " ..   ..    ...                                  ...                 ...  \n",
       " 531  AR  33901       Pulaski Bank and Trust Company         May 9, 2008  \n",
       " 532  MO   1971                        Security Bank       March 7, 2008  \n",
       " 533  MO  24660       Liberty Bank and Trust Company    January 25, 2008  \n",
       " 534  OH  16848         The Citizens Banking Company     October 4, 2007  \n",
       " 535  GA  32575                           ING DIRECT  September 28, 2007  \n",
       " 536  PA  35353  Allegheny Valley Bank of Pittsburgh    February 2, 2007  \n",
       " 537  UT   1249                        Far West Bank       June 25, 2004  \n",
       " 538  NY  26778                     Union State Bank      March 19, 2004  \n",
       " 539  FL  26838              Hancock Bank of Florida      March 12, 2004  \n",
       " 540  NJ  31330                          No Acquirer   February 14, 2004  \n",
       " 541  PA  27203                       Earthstar Bank   November 14, 2003  \n",
       " 542  WI  11639                        The Park Bank         May 9, 2003  \n",
       " 543  CA  27094                            Beal Bank    February 7, 2003  \n",
       " 544  LA  16445            Sabine State Bank & Trust   December 17, 2002  \n",
       " 545  TN   9961                          No Acquirer    November 8, 2002  \n",
       " 546  GA  33784                          No Acquirer  September 30, 2002  \n",
       " 547  IL  29355               Chicago Community Bank       June 27, 2002  \n",
       " 548  CT  19183                   Hudson United Bank       June 26, 2002  \n",
       " 549  MI  34979                          No Acquirer      March 28, 2002  \n",
       " 550  FL  26652                       Bank Leumi USA       March 1, 2002  \n",
       " 551  AZ  22314                          No Acquirer    February 7, 2002  \n",
       " 552  OH   8966       The State Bank & Trust Company    February 1, 2002  \n",
       " 553  TX  22002     The Security State Bank of Pecos    January 18, 2002  \n",
       " 554  FL  24382     Israel Discount Bank of New York    January 11, 2002  \n",
       " 555  AR  34248                   Delta Trust & Bank   September 7, 2001  \n",
       " 556  IL  32646                Superior Federal, FSB       July 27, 2001  \n",
       " 557  OH   6629                    North Valley Bank         May 3, 2001  \n",
       " 558  NH  34264  Southern New Hampshire Bank & Trust    February 2, 2001  \n",
       " 559  IL   3815              Banterra Bank of Marion   December 14, 2000  \n",
       " 560  HI  21029                   Bank of the Orient    October 13, 2000  \n",
       " \n",
       " [561 rows x 6 columns]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaWhHAk9NQtQ"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here is an example that includes a nice parser class: http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ppLnAmKVNQtQ"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VB9EoRrNQtS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>datetime</th>\n",
       "      <th>integer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category            datetime  integer\n",
       "0          0 2015-01-01 00:00:00        5\n",
       "1          0 2015-01-01 00:00:01        5\n",
       "10         0 2015-01-01 00:00:10        5\n",
       "11         0 2015-01-01 00:00:11        5\n",
       "12         0 2015-01-01 00:00:12        8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIArBrFFNQtV"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aFUJrhENQtW"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmjox61xNQtW"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29PQdqUMNQtX"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04lspVeiNQtY"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkO6SxSmNQtY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.shape\n",
    "#Answer: 17 columns and 17379 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "camJWA-DNQta"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDzIHgjXNQtb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'instant', u'dteday', u'season', u'yr', u'mnth', u'hr', u'holiday',\n",
       "       u'weekday', u'workingday', u'weathersit', u'temp', u'atemp', u'hum',\n",
       "       u'windspeed', u'casual', u'registered', u'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.columns\n",
    "#Answer: u'instant', u'dteday', u'season', u'yr', u'mnth', u'hr', u'holiday', u'weekday', u'workingday', u'weathersit', u'temp', u'atemp', u'hum',u'windspeed', u'casual', u'registered', u'cnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iL7Cm_4NNQtc"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtKQtrdSNQtd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.dtypes\n",
    "#12 columns are integers (full numbers) except for dteday which is a date and the following which are floats (numbers with decimals): temp, atemp, hum, windespeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqHDi7_GNQtf"
   },
   "source": [
    "What is the (row) index for this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7WciAwrNQtf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=17379, step=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIJcLnsKNQth"
   },
   "source": [
    "https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtxBEejpNQti"
   },
   "source": [
    "## Slicing and Dicing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "Tzns_pFsNQtj"
   },
   "source": [
    "# It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this. \n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSlC2oZXNQtj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17349</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17350</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17351</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17352</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17353</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17354</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17356</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17358</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17360</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17361</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17362</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17364</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17365</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17366</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17367</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17369</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17370</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           1\n",
       "5           1\n",
       "6           1\n",
       "7           1\n",
       "8           1\n",
       "9           1\n",
       "10          1\n",
       "11          1\n",
       "12          1\n",
       "13          1\n",
       "14          1\n",
       "15          1\n",
       "16          1\n",
       "17          1\n",
       "18          1\n",
       "19          1\n",
       "20          1\n",
       "21          1\n",
       "22          1\n",
       "23          1\n",
       "24          1\n",
       "25          1\n",
       "26          1\n",
       "27          1\n",
       "28          1\n",
       "29          1\n",
       "...       ...\n",
       "17349       1\n",
       "17350       1\n",
       "17351       1\n",
       "17352       1\n",
       "17353       1\n",
       "17354       1\n",
       "17355       1\n",
       "17356       1\n",
       "17357       1\n",
       "17358       1\n",
       "17359       1\n",
       "17360       1\n",
       "17361       1\n",
       "17362       1\n",
       "17363       1\n",
       "17364       1\n",
       "17365       1\n",
       "17366       1\n",
       "17367       1\n",
       "17368       1\n",
       "17369       1\n",
       "17370       1\n",
       "17371       1\n",
       "17372       1\n",
       "17373       1\n",
       "17374       1\n",
       "17375       1\n",
       "17376       1\n",
       "17377       1\n",
       "17378       1\n",
       "\n",
       "[17379 rows x 1 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER bikes[['season']] returns a cleaner table with headings and grid whereas bikes['season'] has row data with no structure\n",
    "bikes[['season']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsCATb2iNQtl"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5D_UU5KNQtm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    atemp\n",
       "0  0.2879\n",
       "1  0.2727\n",
       "2  0.2727\n",
       "3  0.2879\n",
       "4  0.2879"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.loc[0:4,['atemp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWKI9FNDNQto"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgWFEEmWNQto"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"None of [Int64Index([0, 0], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-5c7c5a0af858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#E: bikes[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#E: bikes[0,0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Perrine Mignot\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: u\"None of [Int64Index([0, 0], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#E: bikes[[0]]\n",
    "#E: bikes[0]\n",
    "#E: bikes[0,0]\n",
    "bikes[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeUJ7D5qNQtq"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4Kidzz0NQtq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZa1v-2jNQts"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4GmE0EsNQtt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01\n",
       "1        2011-01-01\n",
       "2        2011-01-01\n",
       "3        2011-01-01\n",
       "4        2011-01-01\n",
       "5        2011-01-01\n",
       "6        2011-01-01\n",
       "7        2011-01-01\n",
       "8        2011-01-01\n",
       "9        2011-01-01\n",
       "10       2011-01-01\n",
       "11       2011-01-01\n",
       "12       2011-01-01\n",
       "13       2011-01-01\n",
       "14       2011-01-01\n",
       "15       2011-01-01\n",
       "16       2011-01-01\n",
       "17       2011-01-01\n",
       "18       2011-01-01\n",
       "19       2011-01-01\n",
       "20       2011-01-01\n",
       "21       2011-01-01\n",
       "22       2011-01-01\n",
       "23       2011-01-01\n",
       "24       2011-01-02\n",
       "25       2011-01-02\n",
       "26       2011-01-02\n",
       "27       2011-01-02\n",
       "28       2011-01-02\n",
       "29       2011-01-02\n",
       "            ...    \n",
       "17349    2012-12-30\n",
       "17350    2012-12-30\n",
       "17351    2012-12-30\n",
       "17352    2012-12-30\n",
       "17353    2012-12-30\n",
       "17354    2012-12-30\n",
       "17355    2012-12-31\n",
       "17356    2012-12-31\n",
       "17357    2012-12-31\n",
       "17358    2012-12-31\n",
       "17359    2012-12-31\n",
       "17360    2012-12-31\n",
       "17361    2012-12-31\n",
       "17362    2012-12-31\n",
       "17363    2012-12-31\n",
       "17364    2012-12-31\n",
       "17365    2012-12-31\n",
       "17366    2012-12-31\n",
       "17367    2012-12-31\n",
       "17368    2012-12-31\n",
       "17369    2012-12-31\n",
       "17370    2012-12-31\n",
       "17371    2012-12-31\n",
       "17372    2012-12-31\n",
       "17373    2012-12-31\n",
       "17374    2012-12-31\n",
       "17375    2012-12-31\n",
       "17376    2012-12-31\n",
       "17377    2012-12-31\n",
       "17378    2012-12-31\n",
       "Name: dteday, Length: 17379, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSvqNbVUNQtu"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRPFEN1HNQtu"
   },
   "source": [
    "What is the Pandas `isnull` function for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xyw5qkWWNQtu"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iby8s2VSNQtv"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRQY-1ViNQtv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season     yr   mnth     hr  holiday  weekday  workingday  \\\n",
       "0    False   False   False  False  False  False    False    False       False   \n",
       "1    False   False   False  False  False  False    False    False       False   \n",
       "2    False   False   False  False  False  False    False    False       False   \n",
       "3    False   False   False  False  False  False    False    False       False   \n",
       "4    False   False   False  False  False  False    False    False       False   \n",
       "\n",
       "   weathersit   temp  atemp    hum  windspeed  casual  registered    cnt  \n",
       "0       False  False  False  False      False   False       False  False  \n",
       "1       False  False  False  False      False   False       False  False  \n",
       "2       False  False  False  False      False   False       False  False  \n",
       "3       False  False  False  False      False   False       False  False  \n",
       "4       False  False  False  False      False   False       False  False  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IyZaICINQtw"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbDfiSqVNQtx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10jWUf4VNQty"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBv3l_s2NQtz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1MsvXf7NQt0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaeGVh6ZNQt0"
   },
   "source": [
    "?\n",
    "ANSWER: Marking a data point as invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9bFlPsrNQt1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge case (i.e. return a value instead of just trapping the error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Cq2VAb8NQt1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
      "0            1  2011-01-01       1   0     1   0        0        6   \n",
      "1            2  2011-01-01       1   0     1   1        0        6   \n",
      "2            3  2011-01-01       1   0     1   2        0        6   \n",
      "3            4  2011-01-01       1   0     1   3        0        6   \n",
      "4            5  2011-01-01       1   0     1   4        0        6   \n",
      "5            6  2011-01-01       1   0     1   5        0        6   \n",
      "6            7  2011-01-01       1   0     1   6        0        6   \n",
      "7            8  2011-01-01       1   0     1   7        0        6   \n",
      "8            9  2011-01-01       1   0     1   8        0        6   \n",
      "9           10  2011-01-01       1   0     1   9        0        6   \n",
      "10          11  2011-01-01       1   0     1  10        0        6   \n",
      "11          12  2011-01-01       1   0     1  11        0        6   \n",
      "12          13  2011-01-01       1   0     1  12        0        6   \n",
      "13          14  2011-01-01       1   0     1  13        0        6   \n",
      "14          15  2011-01-01       1   0     1  14        0        6   \n",
      "15          16  2011-01-01       1   0     1  15        0        6   \n",
      "16          17  2011-01-01       1   0     1  16        0        6   \n",
      "17          18  2011-01-01       1   0     1  17        0        6   \n",
      "18          19  2011-01-01       1   0     1  18        0        6   \n",
      "19          20  2011-01-01       1   0     1  19        0        6   \n",
      "20          21  2011-01-01       1   0     1  20        0        6   \n",
      "21          22  2011-01-01       1   0     1  21        0        6   \n",
      "22          23  2011-01-01       1   0     1  22        0        6   \n",
      "23          24  2011-01-01       1   0     1  23        0        6   \n",
      "24          25  2011-01-02       1   0     1   0        0        0   \n",
      "25          26  2011-01-02       1   0     1   1        0        0   \n",
      "26          27  2011-01-02       1   0     1   2        0        0   \n",
      "27          28  2011-01-02       1   0     1   3        0        0   \n",
      "28          29  2011-01-02       1   0     1   4        0        0   \n",
      "29          30  2011-01-02       1   0     1   6        0        0   \n",
      "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
      "17349    17350  2012-12-30       1   1    12  18        0        0   \n",
      "17350    17351  2012-12-30       1   1    12  19        0        0   \n",
      "17351    17352  2012-12-30       1   1    12  20        0        0   \n",
      "17352    17353  2012-12-30       1   1    12  21        0        0   \n",
      "17353    17354  2012-12-30       1   1    12  22        0        0   \n",
      "17354    17355  2012-12-30       1   1    12  23        0        0   \n",
      "17355    17356  2012-12-31       1   1    12   0        0        1   \n",
      "17356    17357  2012-12-31       1   1    12   1        0        1   \n",
      "17357    17358  2012-12-31       1   1    12   2        0        1   \n",
      "17358    17359  2012-12-31       1   1    12   3        0        1   \n",
      "17359    17360  2012-12-31       1   1    12   4        0        1   \n",
      "17360    17361  2012-12-31       1   1    12   5        0        1   \n",
      "17361    17362  2012-12-31       1   1    12   6        0        1   \n",
      "17362    17363  2012-12-31       1   1    12   7        0        1   \n",
      "17363    17364  2012-12-31       1   1    12   8        0        1   \n",
      "17364    17365  2012-12-31       1   1    12   9        0        1   \n",
      "17365    17366  2012-12-31       1   1    12  10        0        1   \n",
      "17366    17367  2012-12-31       1   1    12  11        0        1   \n",
      "17367    17368  2012-12-31       1   1    12  12        0        1   \n",
      "17368    17369  2012-12-31       1   1    12  13        0        1   \n",
      "17369    17370  2012-12-31       1   1    12  14        0        1   \n",
      "17370    17371  2012-12-31       1   1    12  15        0        1   \n",
      "17371    17372  2012-12-31       1   1    12  16        0        1   \n",
      "17372    17373  2012-12-31       1   1    12  17        0        1   \n",
      "17373    17374  2012-12-31       1   1    12  18        0        1   \n",
      "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
      "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
      "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
      "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
      "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
      "\n",
      "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
      "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
      "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
      "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
      "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
      "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
      "5               0           2  0.24  0.2576  0.75     0.0896       0   \n",
      "6               0           1  0.22  0.2727  0.80     0.0000       2   \n",
      "7               0           1  0.20  0.2576  0.86     0.0000       1   \n",
      "8               0           1  0.24  0.2879  0.75     0.0000       1   \n",
      "9               0           1  0.32  0.3485  0.76     0.0000       8   \n",
      "10              0           1  0.38  0.3939  0.76     0.2537      12   \n",
      "11              0           1  0.36  0.3333  0.81     0.2836      26   \n",
      "12              0           1  0.42  0.4242  0.77     0.2836      29   \n",
      "13              0           2  0.46  0.4545  0.72     0.2985      47   \n",
      "14              0           2  0.46  0.4545  0.72     0.2836      35   \n",
      "15              0           2  0.44  0.4394  0.77     0.2985      40   \n",
      "16              0           2  0.42  0.4242  0.82     0.2985      41   \n",
      "17              0           2  0.44  0.4394  0.82     0.2836      15   \n",
      "18              0           3  0.42  0.4242  0.88     0.2537       9   \n",
      "19              0           3  0.42  0.4242  0.88     0.2537       6   \n",
      "20              0           2  0.40  0.4091  0.87     0.2537      11   \n",
      "21              0           2  0.40  0.4091  0.87     0.1940       3   \n",
      "22              0           2  0.40  0.4091  0.94     0.2239      11   \n",
      "23              0           2  0.46  0.4545  0.88     0.2985      15   \n",
      "24              0           2  0.46  0.4545  0.88     0.2985       4   \n",
      "25              0           2  0.44  0.4394  0.94     0.2537       1   \n",
      "26              0           2  0.42  0.4242  1.00     0.2836       1   \n",
      "27              0           2  0.46  0.4545  0.94     0.1940       2   \n",
      "28              0           2  0.46  0.4545  0.94     0.1940       2   \n",
      "29              0           3  0.42  0.4242  0.77     0.2985       0   \n",
      "...           ...         ...   ...     ...   ...        ...     ...   \n",
      "17349           0           2  0.24  0.2121  0.44     0.2985      12   \n",
      "17350           0           1  0.34  0.3636  0.61     0.0000      16   \n",
      "17351           0           1  0.22  0.1970  0.47     0.3284       9   \n",
      "17352           0           1  0.20  0.2121  0.51     0.1642       5   \n",
      "17353           0           1  0.20  0.1970  0.55     0.1940       6   \n",
      "17354           0           1  0.20  0.1970  0.51     0.2239      10   \n",
      "17355           1           1  0.18  0.1818  0.55     0.1940       4   \n",
      "17356           1           1  0.18  0.1818  0.55     0.1940       6   \n",
      "17357           1           1  0.16  0.1667  0.59     0.1642       3   \n",
      "17358           1           1  0.16  0.1818  0.59     0.1045       0   \n",
      "17359           1           1  0.14  0.1667  0.69     0.1045       0   \n",
      "17360           1           1  0.16  0.1515  0.64     0.1940       0   \n",
      "17361           1           1  0.16  0.1667  0.64     0.1642       0   \n",
      "17362           1           1  0.16  0.1818  0.64     0.1343       2   \n",
      "17363           1           1  0.14  0.1515  0.69     0.1343       9   \n",
      "17364           1           2  0.18  0.2121  0.64     0.1045      13   \n",
      "17365           1           2  0.20  0.2121  0.69     0.1343      33   \n",
      "17366           1           2  0.22  0.2273  0.60     0.1940      43   \n",
      "17367           1           2  0.24  0.2273  0.56     0.1940      52   \n",
      "17368           1           2  0.26  0.2576  0.44     0.1642      38   \n",
      "17369           1           2  0.28  0.2727  0.45     0.2239      62   \n",
      "17370           1           2  0.28  0.2879  0.45     0.1343      69   \n",
      "17371           1           2  0.26  0.2576  0.48     0.1940      30   \n",
      "17372           1           2  0.26  0.2879  0.48     0.0896      14   \n",
      "17373           1           2  0.26  0.2727  0.48     0.1343      10   \n",
      "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
      "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
      "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
      "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
      "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
      "\n",
      "       registered  cnt  \n",
      "0              13   16  \n",
      "1              32   40  \n",
      "2              27   32  \n",
      "3              10   13  \n",
      "4               1    1  \n",
      "5               1    1  \n",
      "6               0    2  \n",
      "7               2    3  \n",
      "8               7    8  \n",
      "9               6   14  \n",
      "10             24   36  \n",
      "11             30   56  \n",
      "12             55   84  \n",
      "13             47   94  \n",
      "14             71  106  \n",
      "15             70  110  \n",
      "16             52   93  \n",
      "17             52   67  \n",
      "18             26   35  \n",
      "19             31   37  \n",
      "20             25   36  \n",
      "21             31   34  \n",
      "22             17   28  \n",
      "23             24   39  \n",
      "24             13   17  \n",
      "25             16   17  \n",
      "26              8    9  \n",
      "27              4    6  \n",
      "28              1    3  \n",
      "29              2    2  \n",
      "...           ...  ...  \n",
      "17349         113  125  \n",
      "17350          86  102  \n",
      "17351          63   72  \n",
      "17352          42   47  \n",
      "17353          30   36  \n",
      "17354          39   49  \n",
      "17355          30   34  \n",
      "17356          13   19  \n",
      "17357           8   11  \n",
      "17358           1    1  \n",
      "17359           3    3  \n",
      "17360           9    9  \n",
      "17361          40   40  \n",
      "17362          83   85  \n",
      "17363         187  196  \n",
      "17364         144  157  \n",
      "17365          87  120  \n",
      "17366         114  157  \n",
      "17367         172  224  \n",
      "17368         165  203  \n",
      "17369         185  247  \n",
      "17370         246  315  \n",
      "17371         184  214  \n",
      "17372         150  164  \n",
      "17373         112  122  \n",
      "17374         108  119  \n",
      "17375          81   89  \n",
      "17376          83   90  \n",
      "17377          48   61  \n",
      "17378          37   49  \n",
      "\n",
      "[17379 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER: acronym for Not a Number. \n",
    "bikes.fillna(0, inplace = True) \n",
    "print(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7Up8D6lNQt2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_YvVav3NQt3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.3, nan)\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAcf1FU1NQt4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(x), pd.isna(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJUM31pANQt5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LBgqnubNQt6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhFaZbzQNQt7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mw-PvrTeNQt8"
   },
   "source": [
    "? ANSWER: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOW3ICgwNQt8"
   },
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZhJ9-XrNQt8"
   },
   "source": [
    "### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RitKNRPCNQt8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqmE4OMsNQt9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4496\n",
       "2    4409\n",
       "1    4242\n",
       "4    4232\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peDZrNJjNQt-"
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIKyD5LHNQt-"
   },
   "source": [
    "Print the range of the `instant`, `dteday`, and `windspeed` columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVAOjyocNQt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('instant:', 1, 'to', 17379)\n",
      "('dteday:', '2011-01-01', 'to', '2012-12-31')\n",
      "('windspeed:', 0.0, 'to', 0.8507)\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print('instant:', bikes['instant'].min(), 'to', bikes['instant'].max())\n",
    "print('dteday:', bikes['dteday'].min(), 'to', bikes['dteday'].max())\n",
    "print('windspeed:', bikes['windspeed'].min(), 'to', bikes['windspeed'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5oDTJHoNQt_"
   },
   "source": [
    "Compute and print the overall minimum and maximum of the numeric data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiIKiPT4NQuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '2012-12-31')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_min, bikes_max = (min(bikes.min()), max(bikes.max()))\n",
    "bikes_min, bikes_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyKKjxJoNQuB"
   },
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hxPA3sXNQuB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1GLqWOoNQuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBWCtrCrNQuD"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu8bzEktNQuD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.2424\n",
       "0.25    0.3333\n",
       "0.50    0.4848\n",
       "0.75    0.6212\n",
       "0.90    0.6970\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp'].quantile((0.1, 0.25, 0.5, 0.75, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJnCB_bqNQuF"
   },
   "source": [
    "### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vn_cvvY-NQuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ae7zUQp-NQuH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bikes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-53654d0e595b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bikes' is not defined"
     ]
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thwFHrthNQuJ"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indcates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7mXBeXMNQuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           (0.25, 0.5]\n",
      "1           (0.25, 0.5]\n",
      "2           (0.25, 0.5]\n",
      "3           (0.25, 0.5]\n",
      "4           (0.25, 0.5]\n",
      "5           (0.25, 0.5]\n",
      "6           (0.25, 0.5]\n",
      "7           (0.25, 0.5]\n",
      "8           (0.25, 0.5]\n",
      "9           (0.25, 0.5]\n",
      "10          (0.25, 0.5]\n",
      "11          (0.25, 0.5]\n",
      "12          (0.25, 0.5]\n",
      "13          (0.25, 0.5]\n",
      "14          (0.25, 0.5]\n",
      "15          (0.25, 0.5]\n",
      "16          (0.25, 0.5]\n",
      "17          (0.25, 0.5]\n",
      "18          (0.25, 0.5]\n",
      "19          (0.25, 0.5]\n",
      "20          (0.25, 0.5]\n",
      "21          (0.25, 0.5]\n",
      "22          (0.25, 0.5]\n",
      "23          (0.25, 0.5]\n",
      "24          (0.25, 0.5]\n",
      "25          (0.25, 0.5]\n",
      "26          (0.25, 0.5]\n",
      "27          (0.25, 0.5]\n",
      "28          (0.25, 0.5]\n",
      "29          (0.25, 0.5]\n",
      "              ...      \n",
      "17349    (-0.001, 0.25]\n",
      "17350       (0.25, 0.5]\n",
      "17351    (-0.001, 0.25]\n",
      "17352    (-0.001, 0.25]\n",
      "17353    (-0.001, 0.25]\n",
      "17354    (-0.001, 0.25]\n",
      "17355    (-0.001, 0.25]\n",
      "17356    (-0.001, 0.25]\n",
      "17357    (-0.001, 0.25]\n",
      "17358    (-0.001, 0.25]\n",
      "17359    (-0.001, 0.25]\n",
      "17360    (-0.001, 0.25]\n",
      "17361    (-0.001, 0.25]\n",
      "17362    (-0.001, 0.25]\n",
      "17363    (-0.001, 0.25]\n",
      "17364    (-0.001, 0.25]\n",
      "17365    (-0.001, 0.25]\n",
      "17366    (-0.001, 0.25]\n",
      "17367    (-0.001, 0.25]\n",
      "17368       (0.25, 0.5]\n",
      "17369       (0.25, 0.5]\n",
      "17370       (0.25, 0.5]\n",
      "17371       (0.25, 0.5]\n",
      "17372       (0.25, 0.5]\n",
      "17373       (0.25, 0.5]\n",
      "17374       (0.25, 0.5]\n",
      "17375       (0.25, 0.5]\n",
      "17376       (0.25, 0.5]\n",
      "17377       (0.25, 0.5]\n",
      "17378       (0.25, 0.5]\n",
      "Name: atemp, Length: 17379, dtype: category\n",
      "Categories (4, interval[float64]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4)     \n",
    "print(atemp_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vf3Q5vbQNQuL"
   },
   "source": [
    "What is `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhlx1W-VNQuL"
   },
   "outputs": [],
   "source": [
    "#ANSWER: it is a split of the atemp column into 4 bins between 0 and 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuDXdgfxNQuN"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Qure0UbNQuN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11920       (0.5, 0.75]\n",
       "17250    (-0.001, 0.25]\n",
       "14082       (0.5, 0.75]\n",
       "14880       (0.25, 0.5]\n",
       "14689       (0.25, 0.5]\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, interval[float64]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q59qWmqfNQuO"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYsD8ZwDNQuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426     mild\n",
       "9244    mild\n",
       "2309    mild\n",
       "2623    mild\n",
       "1445    mild\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): [cool < mild < warm < hot]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD-3g9qLNQuQ"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5fRRbXwNQuR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp_level'] = atemp_level\n",
    "bikes[(bikes.atemp_level == 'mild') & (bikes.season == 2)].season.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZN-0yDQNQuR"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxMDzgRWNQuS"
   },
   "source": [
    "# Synthetic Data\n",
    "\n",
    "Sometimes we may want to generate test data, or we may need to initalise a series, matrix, or data frame for input to an algorithm. Numpy has several methods we can use for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_W10uoBlNQuS"
   },
   "source": [
    "Execute the following, then check the shape and content of each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFR29OriNQuS"
   },
   "outputs": [],
   "source": [
    "# Creating arrays with initial values\n",
    "a = np.zeros((3))\n",
    "b = np.ones((1,3))\n",
    "c = np.random.randint(1,10,(2,3,4))   # randint(low, high, size)\n",
    "d = np.arange(4)\n",
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGrvvNNANQuT"
   },
   "outputs": [],
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JykYEjUHVppc"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load rock.csv and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Clean</th>\n",
       "      <th>ARTIST CLEAN</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>COMBINED</th>\n",
       "      <th>First?</th>\n",
       "      <th>Year?</th>\n",
       "      <th>PlayCount</th>\n",
       "      <th>F*G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caught Up in You</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1982</td>\n",
       "      <td>Caught Up in You by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantasy Girl</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fantasy Girl by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold On Loosely</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1981</td>\n",
       "      <td>Hold On Loosely by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rockin' Into the Night</td>\n",
       "      <td>.38 Special</td>\n",
       "      <td>1980</td>\n",
       "      <td>Rockin' Into the Night by .38 Special</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>10cc</td>\n",
       "      <td>1975</td>\n",
       "      <td>Art For Arts Sake by 10cc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song Clean ARTIST CLEAN Release Year  \\\n",
       "0        Caught Up in You  .38 Special         1982   \n",
       "1            Fantasy Girl  .38 Special          NaN   \n",
       "2         Hold On Loosely  .38 Special         1981   \n",
       "3  Rockin' Into the Night  .38 Special         1980   \n",
       "4       Art For Arts Sake         10cc         1975   \n",
       "\n",
       "                                COMBINED  First?  Year?  PlayCount  F*G  \n",
       "0        Caught Up in You by .38 Special       1      1         82   82  \n",
       "1            Fantasy Girl by .38 Special       1      0          3    0  \n",
       "2         Hold On Loosely by .38 Special       1      1         85   85  \n",
       "3  Rockin' Into the Night by .38 Special       1      1         18   18  \n",
       "4              Art For Arts Sake by 10cc       1      1          1    1  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock = pd.read_csv(\"rock.csv\")\n",
    "rock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZQ4WoVYVppf"
   },
   "source": [
    "## Check Column Names\n",
    "\n",
    "Check column names and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Song Clean', u'ARTIST CLEAN', u'Release Year', u'COMBINED', u'First?',\n",
       "       u'Year?', u'PlayCount', u'F*G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'song_clean', u'artist_clean', u'release_year', u'combined', u'first',\n",
       "       u'year', u'playcount', u'fg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.columns = rock.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('?', '').str.replace('*', '').str.replace('(', '').str.replace(')', '')\n",
    "rock.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KToV3ub3Vppg"
   },
   "source": [
    "# Replace Null Values With 0\n",
    "\n",
    "Check 'release' column whether this column have any null value or not. Replace null value with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Clean        0\n",
       "ARTIST CLEAN      0\n",
       "Release Year    577\n",
       "COMBINED          0\n",
       "First?            0\n",
       "Year?             0\n",
       "PlayCount         0\n",
       "F*G               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       song_clean   artist_clean  \\\n",
      "0                                Caught Up in You    .38 Special   \n",
      "1                                    Fantasy Girl    .38 Special   \n",
      "2                                 Hold On Loosely    .38 Special   \n",
      "3                          Rockin' Into the Night    .38 Special   \n",
      "4                               Art For Arts Sake           10cc   \n",
      "5                                      Kryptonite   3 Doors Down   \n",
      "6                                           Loser   3 Doors Down   \n",
      "7                                   When I'm Gone   3 Doors Down   \n",
      "8                                      What's Up?  4 Non Blondes   \n",
      "9                                      Take On Me           a-ha   \n",
      "10                          Baby, Please Don't Go          AC/DC   \n",
      "11                                  Back In Black          AC/DC   \n",
      "12                                        Big Gun          AC/DC   \n",
      "13                         CAN'T STOP ROCK'N'ROLL          AC/DC   \n",
      "14                    Dirty Deeds Done Dirt Cheap          AC/DC   \n",
      "15                        For Those About To Rock          AC/DC   \n",
      "16                               Girls Got Rhythm          AC/DC   \n",
      "17                                 Hard As A Rock          AC/DC   \n",
      "18                             Have a Drink On Me          AC/DC   \n",
      "19                                    Hells Bells          AC/DC   \n",
      "20                                Highway To Hell          AC/DC   \n",
      "21                     It's A Long Way To The Top          AC/DC   \n",
      "22                                      Jailbreak          AC/DC   \n",
      "23                              Let There Be Rock          AC/DC   \n",
      "24                                Let's Get It Up          AC/DC   \n",
      "25                                      Live Wire          AC/DC   \n",
      "26                                     Moneytalks          AC/DC   \n",
      "27                                  Night Prowler          AC/DC   \n",
      "28            Rock and Roll Ain't Noise Pollution          AC/DC   \n",
      "29                                Shoot To Thrill          AC/DC   \n",
      "...                                           ...            ...   \n",
      "2200                      Owner of a Lonely Heart            Yes   \n",
      "2201                                   Roundabout            Yes   \n",
      "2202                             Starship Trooper            Yes   \n",
      "2203                            Wonderous Stories            Yes   \n",
      "2204                         Yours Is No Disgrace            Yes   \n",
      "2205                        Tell Me What You Want          Zebra   \n",
      "2206                        Who's Behind The Door          Zebra   \n",
      "2207                           Time of the Season        Zombies   \n",
      "2208                    A Fool for Your Stockings         ZZ Top   \n",
      "2209             Arrested For Driving While Blind         ZZ Top   \n",
      "2210                 Beer Drinkers & Hell Raisers         ZZ Top   \n",
      "2211                             Cheap Sunglasses         ZZ Top   \n",
      "2212                         Gimme All Your Lovin         ZZ Top   \n",
      "2213                        Got Me Under Pressure         ZZ Top   \n",
      "2214                            Heard It On the X         ZZ Top   \n",
      "2215                                  I Thank You         ZZ Top   \n",
      "2216                      I'm Bad, I'm Nationwide         ZZ Top   \n",
      "2217                      Jesus Just Left Chicago         ZZ Top   \n",
      "2218                                Just Got Paid         ZZ Top   \n",
      "2219                                    La Grange         ZZ Top   \n",
      "2220                                         Legs         ZZ Top   \n",
      "2221                     My Head's In Mississippi         ZZ Top   \n",
      "2222                           Party On The Patio         ZZ Top   \n",
      "2223                               Pearl Necklace         ZZ Top   \n",
      "2224                            Sharp Dressed Man         ZZ Top   \n",
      "2225                      She Loves My Automobile         ZZ Top   \n",
      "2226                            Tube Snake Boogie         ZZ Top   \n",
      "2227                                         Tush         ZZ Top   \n",
      "2228                                   TV Dinners         ZZ Top   \n",
      "2229  WAITIN' FOR THE BUS/JESUS JUST LEFT CHICAGO         ZZ Top   \n",
      "\n",
      "      release_year                                           combined  first  \\\n",
      "0           1982.0                    Caught Up in You by .38 Special      1   \n",
      "1              0.0                        Fantasy Girl by .38 Special      1   \n",
      "2           1981.0                     Hold On Loosely by .38 Special      1   \n",
      "3           1980.0              Rockin' Into the Night by .38 Special      1   \n",
      "4           1975.0                          Art For Arts Sake by 10cc      1   \n",
      "5           2000.0                         Kryptonite by 3 Doors Down      1   \n",
      "6           2000.0                              Loser by 3 Doors Down      1   \n",
      "7           2002.0                      When I'm Gone by 3 Doors Down      1   \n",
      "8           1992.0                        What's Up? by 4 Non Blondes      1   \n",
      "9           1985.0                                 Take On Me by a-ha      1   \n",
      "10             0.0                     Baby, Please Don't Go by AC/DC      1   \n",
      "11          1980.0                             Back In Black by AC/DC      1   \n",
      "12          1993.0                                   Big Gun by AC/DC      1   \n",
      "13             0.0                    CAN'T STOP ROCK'N'ROLL by AC/DC      1   \n",
      "14          1976.0               Dirty Deeds Done Dirt Cheap by AC/DC      1   \n",
      "15          1981.0                   For Those About To Rock by AC/DC      1   \n",
      "16             0.0                          Girls Got Rhythm by AC/DC      1   \n",
      "17          1995.0                            Hard As A Rock by AC/DC      1   \n",
      "18          1980.0                        Have a Drink On Me by AC/DC      1   \n",
      "19          1980.0                               Hells Bells by AC/DC      1   \n",
      "20          1979.0                           Highway To Hell by AC/DC      1   \n",
      "21          1975.0                It's A Long Way To The Top by AC/DC      1   \n",
      "22          1984.0                                 Jailbreak by AC/DC      1   \n",
      "23          1977.0                         Let There Be Rock by AC/DC      1   \n",
      "24             0.0                           Let's Get It Up by AC/DC      1   \n",
      "25             0.0                                 Live Wire by AC/DC      1   \n",
      "26             0.0                                Moneytalks by AC/DC      1   \n",
      "27          1979.0                             Night Prowler by AC/DC      1   \n",
      "28          1980.0       Rock and Roll Ain't Noise Pollution by AC/DC      1   \n",
      "29             0.0                           Shoot To Thrill by AC/DC      1   \n",
      "...            ...                                                ...    ...   \n",
      "2200        1983.0                     Owner of a Lonely Heart by Yes      1   \n",
      "2201        1971.0                                  Roundabout by Yes      1   \n",
      "2202        1971.0                            Starship Trooper by Yes      1   \n",
      "2203           0.0                           Wonderous Stories by Yes      1   \n",
      "2204        1971.0                        Yours Is No Disgrace by Yes      1   \n",
      "2205           0.0                     Tell Me What You Want by Zebra      1   \n",
      "2206           0.0                     Who's Behind The Door by Zebra      1   \n",
      "2207        1968.0                      Time of the Season by Zombies      1   \n",
      "2208           0.0                A Fool for Your Stockings by ZZ Top      1   \n",
      "2209        1976.0         Arrested For Driving While Blind by ZZ Top      1   \n",
      "2210        1973.0             Beer Drinkers & Hell Raisers by ZZ Top      1   \n",
      "2211        1980.0                         Cheap Sunglasses by ZZ Top      1   \n",
      "2212        1983.0                     Gimme All Your Lovin by ZZ Top      1   \n",
      "2213        1983.0                    Got Me Under Pressure by ZZ Top      1   \n",
      "2214        1975.0                        Heard It On the X by ZZ Top      1   \n",
      "2215           0.0                              I Thank You by ZZ Top      1   \n",
      "2216           0.0                  I'm Bad, I'm Nationwide by ZZ Top      1   \n",
      "2217        1973.0                  Jesus Just Left Chicago by ZZ Top      1   \n",
      "2218           0.0                            Just Got Paid by ZZ Top      1   \n",
      "2219        1973.0                                La Grange by ZZ Top      1   \n",
      "2220        1983.0                                     Legs by ZZ Top      1   \n",
      "2221           0.0                 My Head's In Mississippi by ZZ Top      1   \n",
      "2222           0.0                       Party On The Patio by ZZ Top      1   \n",
      "2223        1981.0                           Pearl Necklace by ZZ Top      1   \n",
      "2224        1983.0                        Sharp Dressed Man by ZZ Top      1   \n",
      "2225           0.0                  She Loves My Automobile by ZZ Top      1   \n",
      "2226        1981.0                        Tube Snake Boogie by ZZ Top      1   \n",
      "2227        1975.0                                     Tush by ZZ Top      1   \n",
      "2228        1983.0                               TV Dinners by ZZ Top      1   \n",
      "2229        1973.0  WAITIN' FOR THE BUS/JESUS JUST LEFT CHICAGO by...      1   \n",
      "\n",
      "      year  playcount   fg  \n",
      "0        1         82   82  \n",
      "1        0          3    0  \n",
      "2        1         85   85  \n",
      "3        1         18   18  \n",
      "4        1          1    1  \n",
      "5        1         13   13  \n",
      "6        1          1    1  \n",
      "7        1          6    6  \n",
      "8        1          3    3  \n",
      "9        1          1    1  \n",
      "10       0          1    0  \n",
      "11       1         97   97  \n",
      "12       1          6    6  \n",
      "13       0          5    0  \n",
      "14       1         85   85  \n",
      "15       1         46   46  \n",
      "16       0         24    0  \n",
      "17       1          1    1  \n",
      "18       1         39   39  \n",
      "19       1         74   74  \n",
      "20       1         92   92  \n",
      "21       1         39   39  \n",
      "22       1          1    1  \n",
      "23       1          3    3  \n",
      "24       0          4    0  \n",
      "25       0          2    0  \n",
      "26       0         20    0  \n",
      "27       1          1    1  \n",
      "28       1         21   21  \n",
      "29       0         45    0  \n",
      "...    ...        ...  ...  \n",
      "2200     1         81   81  \n",
      "2201     1         44   44  \n",
      "2202     1          1    1  \n",
      "2203     0          5    0  \n",
      "2204     1          1    1  \n",
      "2205     0          2    0  \n",
      "2206     0          1    0  \n",
      "2207     1         14   14  \n",
      "2208     0          1    0  \n",
      "2209     1          1    1  \n",
      "2210     1          8    8  \n",
      "2211     1         34   34  \n",
      "2212     1         86   86  \n",
      "2213     1         29   29  \n",
      "2214     1          2    2  \n",
      "2215     0         16    0  \n",
      "2216     0         10    0  \n",
      "2217     1          6    6  \n",
      "2218     0          2    0  \n",
      "2219     1        111  111  \n",
      "2220     1        121  121  \n",
      "2221     0          1    0  \n",
      "2222     0         14    0  \n",
      "2223     1          5    5  \n",
      "2224     1        120  120  \n",
      "2225     0          1    0  \n",
      "2226     1         32   32  \n",
      "2227     1        109  109  \n",
      "2228     1          1    1  \n",
      "2229     1          2    2  \n",
      "\n",
      "[2230 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "rock.fillna(0, inplace = True) \n",
    "print(rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQ2GyN7MVpph"
   },
   "source": [
    "# Check Datatypes of Dataset\n",
    "\n",
    "Check datatypes of the dataset. Is there any column which should be int instead of object? Fix the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock['release_year'].apply(pd.to_numeric)\n",
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCzoReoXVpph"
   },
   "source": [
    "# Check Min, Max of Each Column\n",
    "\n",
    "Is there any illogical value in any column? How can we fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     #9 Dream\n",
       "artist_clean                .38 Special\n",
       "release_year                          0\n",
       "combined        #9 Dream by John Lennon\n",
       "first                                 1\n",
       "year                                  0\n",
       "playcount                             0\n",
       "fg                                    0\n",
       "dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     Ziggy Stardust\n",
       "artist_clean                             a-ha\n",
       "release_year                             2014\n",
       "combined        Ziggy Stardust by David Bowie\n",
       "first                                       1\n",
       "year                                        1\n",
       "playcount                                 142\n",
       "fg                                        142\n",
       "dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       578\n",
       "1973.0    104\n",
       "1975.0     83\n",
       "1977.0     83\n",
       "1970.0     81\n",
       "1971.0     75\n",
       "1969.0     72\n",
       "1980.0     70\n",
       "1978.0     64\n",
       "1979.0     63\n",
       "1981.0     61\n",
       "1967.0     61\n",
       "1983.0     60\n",
       "1976.0     56\n",
       "1982.0     54\n",
       "1984.0     51\n",
       "1972.0     50\n",
       "1974.0     48\n",
       "1968.0     46\n",
       "1985.0     39\n",
       "1987.0     39\n",
       "1986.0     37\n",
       "1991.0     34\n",
       "1989.0     32\n",
       "1966.0     30\n",
       "1988.0     29\n",
       "1965.0     28\n",
       "1994.0     25\n",
       "1990.0     22\n",
       "1993.0     19\n",
       "1992.0     14\n",
       "1964.0     14\n",
       "1999.0     13\n",
       "1995.0     10\n",
       "1997.0      9\n",
       "1963.0      9\n",
       "1996.0      9\n",
       "1998.0      6\n",
       "2002.0      6\n",
       "2005.0      5\n",
       "2012.0      5\n",
       "2004.0      5\n",
       "2001.0      4\n",
       "1962.0      3\n",
       "2000.0      3\n",
       "2007.0      3\n",
       "2003.0      3\n",
       "2011.0      3\n",
       "2008.0      3\n",
       "2013.0      2\n",
       "2014.0      2\n",
       "1961.0      1\n",
       "2006.0      1\n",
       "1958.0      1\n",
       "1955.0      1\n",
       "1071.0      1\n",
       "Name: release_year, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock['release_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzJieuuyVppi"
   },
   "source": [
    "# Write Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jYAjnOVVppi"
   },
   "source": [
    "## Write a function that will take a row of a DataFrame and print out the song, artist, and whether or not the release date is < 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_detail(row):\n",
    "    print('Song: ',row['song_clean'])\n",
    "    print('Artist: ',row['artist_clean'])\n",
    "    print('released before 1970: ',row['release_year'] < 1970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     Caught Up in You\n",
       "artist_clean                        .38 Special\n",
       "release_year                               1982\n",
       "combined        Caught Up in You by .38 Special\n",
       "first                                         1\n",
       "year                                          1\n",
       "playcount                                    82\n",
       "fg                                           82\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Song: ', 'Caught Up in You')\n",
      "('Artist: ', '.38 Special')\n",
      "('released before 1970: ', False)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "track_detail(rock.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk1XfgtkVppj"
   },
   "source": [
    "## Write a function that converts cells in a DataFrame to float and otherwise replaces them with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(column):\n",
    "    column = pd.to_numeric(column, errors='coerce')\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEIsPER2Vppj"
   },
   "source": [
    "## Apply these functions to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_clean</th>\n",
       "      <th>artist_clean</th>\n",
       "      <th>release_year</th>\n",
       "      <th>combined</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2230 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_clean  artist_clean  release_year  combined  first  year  \\\n",
       "0            NaN           NaN        1982.0       NaN      1     1   \n",
       "1            NaN           NaN           0.0       NaN      1     0   \n",
       "2            NaN           NaN        1981.0       NaN      1     1   \n",
       "3            NaN           NaN        1980.0       NaN      1     1   \n",
       "4            NaN           NaN        1975.0       NaN      1     1   \n",
       "5            NaN           NaN        2000.0       NaN      1     1   \n",
       "6            NaN           NaN        2000.0       NaN      1     1   \n",
       "7            NaN           NaN        2002.0       NaN      1     1   \n",
       "8            NaN           NaN        1992.0       NaN      1     1   \n",
       "9            NaN           NaN        1985.0       NaN      1     1   \n",
       "10           NaN           NaN           0.0       NaN      1     0   \n",
       "11           NaN           NaN        1980.0       NaN      1     1   \n",
       "12           NaN           NaN        1993.0       NaN      1     1   \n",
       "13           NaN           NaN           0.0       NaN      1     0   \n",
       "14           NaN           NaN        1976.0       NaN      1     1   \n",
       "15           NaN           NaN        1981.0       NaN      1     1   \n",
       "16           NaN           NaN           0.0       NaN      1     0   \n",
       "17           NaN           NaN        1995.0       NaN      1     1   \n",
       "18           NaN           NaN        1980.0       NaN      1     1   \n",
       "19           NaN           NaN        1980.0       NaN      1     1   \n",
       "20           NaN           NaN        1979.0       NaN      1     1   \n",
       "21           NaN           NaN        1975.0       NaN      1     1   \n",
       "22           NaN           NaN        1984.0       NaN      1     1   \n",
       "23           NaN           NaN        1977.0       NaN      1     1   \n",
       "24           NaN           NaN           0.0       NaN      1     0   \n",
       "25           NaN           NaN           0.0       NaN      1     0   \n",
       "26           NaN           NaN           0.0       NaN      1     0   \n",
       "27           NaN           NaN        1979.0       NaN      1     1   \n",
       "28           NaN           NaN        1980.0       NaN      1     1   \n",
       "29           NaN           NaN           0.0       NaN      1     0   \n",
       "...          ...           ...           ...       ...    ...   ...   \n",
       "2200         NaN           NaN        1983.0       NaN      1     1   \n",
       "2201         NaN           NaN        1971.0       NaN      1     1   \n",
       "2202         NaN           NaN        1971.0       NaN      1     1   \n",
       "2203         NaN           NaN           0.0       NaN      1     0   \n",
       "2204         NaN           NaN        1971.0       NaN      1     1   \n",
       "2205         NaN           NaN           0.0       NaN      1     0   \n",
       "2206         NaN           NaN           0.0       NaN      1     0   \n",
       "2207         NaN           NaN        1968.0       NaN      1     1   \n",
       "2208         NaN           NaN           0.0       NaN      1     0   \n",
       "2209         NaN           NaN        1976.0       NaN      1     1   \n",
       "2210         NaN           NaN        1973.0       NaN      1     1   \n",
       "2211         NaN           NaN        1980.0       NaN      1     1   \n",
       "2212         NaN           NaN        1983.0       NaN      1     1   \n",
       "2213         NaN           NaN        1983.0       NaN      1     1   \n",
       "2214         NaN           NaN        1975.0       NaN      1     1   \n",
       "2215         NaN           NaN           0.0       NaN      1     0   \n",
       "2216         NaN           NaN           0.0       NaN      1     0   \n",
       "2217         NaN           NaN        1973.0       NaN      1     1   \n",
       "2218         NaN           NaN           0.0       NaN      1     0   \n",
       "2219         NaN           NaN        1973.0       NaN      1     1   \n",
       "2220         NaN           NaN        1983.0       NaN      1     1   \n",
       "2221         NaN           NaN           0.0       NaN      1     0   \n",
       "2222         NaN           NaN           0.0       NaN      1     0   \n",
       "2223         NaN           NaN        1981.0       NaN      1     1   \n",
       "2224         NaN           NaN        1983.0       NaN      1     1   \n",
       "2225         NaN           NaN           0.0       NaN      1     0   \n",
       "2226         NaN           NaN        1981.0       NaN      1     1   \n",
       "2227         NaN           NaN        1975.0       NaN      1     1   \n",
       "2228         NaN           NaN        1983.0       NaN      1     1   \n",
       "2229         NaN           NaN        1973.0       NaN      1     1   \n",
       "\n",
       "      playcount   fg  \n",
       "0            82   82  \n",
       "1             3    0  \n",
       "2            85   85  \n",
       "3            18   18  \n",
       "4             1    1  \n",
       "5            13   13  \n",
       "6             1    1  \n",
       "7             6    6  \n",
       "8             3    3  \n",
       "9             1    1  \n",
       "10            1    0  \n",
       "11           97   97  \n",
       "12            6    6  \n",
       "13            5    0  \n",
       "14           85   85  \n",
       "15           46   46  \n",
       "16           24    0  \n",
       "17            1    1  \n",
       "18           39   39  \n",
       "19           74   74  \n",
       "20           92   92  \n",
       "21           39   39  \n",
       "22            1    1  \n",
       "23            3    3  \n",
       "24            4    0  \n",
       "25            2    0  \n",
       "26           20    0  \n",
       "27            1    1  \n",
       "28           21   21  \n",
       "29           45    0  \n",
       "...         ...  ...  \n",
       "2200         81   81  \n",
       "2201         44   44  \n",
       "2202          1    1  \n",
       "2203          5    0  \n",
       "2204          1    1  \n",
       "2205          2    0  \n",
       "2206          1    0  \n",
       "2207         14   14  \n",
       "2208          1    0  \n",
       "2209          1    1  \n",
       "2210          8    8  \n",
       "2211         34   34  \n",
       "2212         86   86  \n",
       "2213         29   29  \n",
       "2214          2    2  \n",
       "2215         16    0  \n",
       "2216         10    0  \n",
       "2217          6    6  \n",
       "2218          2    0  \n",
       "2219        111  111  \n",
       "2220        121  121  \n",
       "2221          1    0  \n",
       "2222         14    0  \n",
       "2223          5    5  \n",
       "2224        120  120  \n",
       "2225          1    0  \n",
       "2226         32   32  \n",
       "2227        109  109  \n",
       "2228          1    1  \n",
       "2229          2    2  \n",
       "\n",
       "[2230 rows x 8 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jz86dxCFVppk"
   },
   "source": [
    "## Describe the new float-only DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj8GdoOXC-Lu"
   },
   "source": [
    "\n",
    "\n",
    "> \n",
    ">\n",
    ">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YLHUmjnDDZq"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Nov8gGCDExO"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2asO3_lDFm8"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q0G5PtA2NQtC",
    "pTkOz1KsNQtK",
    "jS7P3oXQNQtL",
    "kGgcXCzyNQtN",
    "CaWhHAk9NQtQ",
    "ppLnAmKVNQtQ",
    "Kmjox61xNQtW",
    "JZhJ9-XrNQt8",
    "peDZrNJjNQt-",
    "OyKKjxJoNQuB",
    "EJnCB_bqNQuF"
   ],
   "name": "IOD_Lab 3.1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
